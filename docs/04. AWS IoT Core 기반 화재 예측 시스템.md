# AWS IoT Core 기반 화재 예측 시스템 - Part 1

## 시스템 아키텍처 개요

```
IoT Devices → AWS IoT Core → AWS Lambda → Amazon Kinesis → 
Real-time Processing → Machine Learning → Alert System
```

## 1. AWS IoT Core 설정

### 1.1 IoT Thing 등록 및 정책 설정

#### IoT 정책 (JSON)
```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "iot:Connect",
                "iot:Publish",
                "iot:Subscribe",
                "iot:Receive"
            ],
            "Resource": [
                "arn:aws:iot:region:account:client/device-*",
                "arn:aws:iot:region:account:topic/fire-prediction/device/*/data",
                "arn:aws:iot:region:account:topic/fire-prediction/alerts/*"
            ]
        }
    ]
}
```

#### IoT Rule 설정
```sql
-- IoT Rule SQL
SELECT 
    deviceId,
    idx,
    status,
    volt,
    voltLow,
    ct as current,
    zct as leakage_current,
    rzct as resistive_leakage,
    pwr as power,
    pcbTemp,
    sensorTemp,
    co,
    voc,
    pFct as power_factor,
    aArc as arc_count,
    timestamp() as timestamp
FROM 'fire-prediction/device/+/data'
WHERE status < 4096
```

### 1.2 Discrete 데이터 파서

```python
import json
import boto3
import numpy as np
from datetime import datetime
import os
import logging

logger = logging.getLogger()
logger.setLevel(logging.INFO)

class DiscreteDataProcessor:
    def __init__(self):
        self.dynamodb = boto3.resource('dynamodb')
        self.kinesis = boto3.client('kinesis')
        self.sns = boto3.client('sns')
        
        # 테이블 참조
        self.raw_data_table = self.dynamodb.Table('FirePrediction-RawData')
        self.device_state_table = self.dynamodb.Table('FirePrediction-DeviceState')
        
    def parse_discrete_data(self, iot_message):
        """Discrete 데이터 파싱 및 정규화"""
        try:
            data = {
                'device_id': iot_message['deviceId'],
                'idx': iot_message['idx'],
                'timestamp': iot_message['timestamp'],
                'status_bits': iot_message['status'],
                
                # 센서 데이터 (Discrete 클래스 필드 매핑)
                'voltage': iot_message['volt'],
                'voltage_low': iot_message['voltLow'],
                'current': iot_message['current'],
                'leakage_current': iot_message['leakage_current'],
                'resistive_leakage': iot_message['resistive_leakage'],
                'power': iot_message['power'],
                'pcb_temperature': iot_message['pcbTemp'],
                'sensor_temperature': iot_message['sensorTemp'],
                'co_gas': iot_message['co'],
                'voc': iot_message['voc'],
                'power_factor': iot_message['power_factor'],
                'arc_count': iot_message['arc_count']
            }
            
            # 상태 비트 분석
            data['alarm_status'] = self.parse_status_bits(iot_message['status'])
            
            # 위험 지표 계산
            data['risk_indicators'] = self.calculate_risk_indicators(data)
            
            return data
            
        except Exception as e:
            logger.error(f"Data parsing error: {e}")
            return None
    
    def parse_status_bits(self, status):
        """상태 비트 분석 (Discrete 클래스 주석 기반)"""
        # Discrete 클래스의 status 필드 주석:
        # 과전압(1), 정전(2), 과전류(3), 누전(총합)(4), 누전(저항성)(5), 
        # 전력량(6), 기판온도(7), 센서온도(8), CO(9), VOC(10), 역률(11), 아크(12)
        
        alarms = {
            'overvoltage': bool(status & (1 << 0)),        # bit 0
            'power_outage': bool(status & (1 << 1)),       # bit 1  
            'overcurrent': bool(status & (1 << 2)),        # bit 2
            'total_leakage': bool(status & (1 << 3)),      # bit 3
            'resistive_leakage': bool(status & (1 << 4)),  # bit 4
            'power_anomaly': bool(status & (1 << 5)),      # bit 5
            'pcb_temp_alarm': bool(status & (1 << 6)),     # bit 6
            'sensor_temp_alarm': bool(status & (1 << 7)),  # bit 7
            'co_alarm': bool(status & (1 << 8)),           # bit 8
            'voc_alarm': bool(status & (1 << 9)),          # bit 9
            'power_factor_alarm': bool(status & (1 << 10)), # bit 10
            'arc_alarm': bool(status & (1 << 11)),         # bit 11
            'communication_error': status >= 4096          # 통신장애
        }
        
        alarms['total_alarm_count'] = sum(1 for k, v in alarms.items() 
                                        if v and k != 'communication_error')
        return alarms
    
    def calculate_risk_indicators(self, data):
        """화재 위험 지표 계산"""
        indicators = {}
        
        # 온도 위험도 (Discrete 주석 기준: 60°C)
        max_temp = max(data['pcb_temperature'], data['sensor_temperature'])
        if max_temp > 60:
            indicators['temperature_risk'] = 'CRITICAL'
            temp_score = 1.0
        elif max_temp > 50:
            indicators['temperature_risk'] = 'HIGH'
            temp_score = 0.7
        elif max_temp > 40:
            indicators['temperature_risk'] = 'MEDIUM'
            temp_score = 0.4
        else:
            indicators['temperature_risk'] = 'LOW'
            temp_score = 0.1
        
        # 전기적 위험도
        electrical_risk_score = 0
        if data['alarm_status']['overvoltage']:
            electrical_risk_score += 0.15
        if data['alarm_status']['overcurrent']:
            electrical_risk_score += 0.20  # 고전류(100A 기준)
        if data['alarm_status']['total_leakage']:
            electrical_risk_score += 0.25  # 누전(8mA 기준)
        if data['arc_count'] > 0:
            electrical_risk_score += min(0.3, data['arc_count'] * 0.05)
        
        # 가스 위험도 (Discrete 주석 기준)
        gas_risk_score = 0
        if data['co_gas'] > 17:  # 17ppm 초과
            gas_risk_score += 0.2
        if data['voc'] > 400:    # 400μg/m³ 초과
            gas_risk_score += 0.15
        
        # 종합 위험도 (0-1 스케일)
        total_risk = min(1.0, temp_score * 0.4 + electrical_risk_score + gas_risk_score)
        
        indicators.update({
            'electrical_risk_score': electrical_risk_score,
            'gas_risk_score': gas_risk_score,
            'temperature_score': temp_score,
            'total_risk_score': total_risk
        })
        
        return indicators

    def validate_discrete_data(self, data):
        """Discrete 데이터 유효성 검증"""
        validation_results = {
            'is_valid': True,
            'warnings': [],
            'errors': []
        }
        
        # verifySts 필드가 있다면 status와 비교 검증
        if 'verifySts' in data:
            if data['verifySts'] != data['status_bits']:
                validation_results['warnings'].append(
                    f"Status verification mismatch: {data['status_bits']} vs {data['verifySts']}"
                )
        
        # 센서 값 범위 검증
        if data['voltage'] < 0 or data['voltage'] > 300:
            validation_results['errors'].append(f"Voltage out of range: {data['voltage']}")
        
        if data['current'] < 0 or data['current'] > 200:
            validation_results['errors'].append(f"Current out of range: {data['current']}")
        
        if data['pcb_temperature'] < -10 or data['pcb_temperature'] > 100:
            validation_results['errors'].append(f"PCB temperature out of range: {data['pcb_temperature']}")
        
        if data['sensor_temperature'] < -10 or data['sensor_temperature'] > 100:
            validation_results['errors'].append(f"Sensor temperature out of range: {data['sensor_temperature']}")
        
        if validation_results['errors']:
            validation_results['is_valid'] = False
        
        return validation_results
```

### 1.3 DynamoDB 테이블 설계

```yaml
# CloudFormation 템플릿
Resources:
  FirePredictionRawDataTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: FirePrediction-RawData
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: device_id
          AttributeType: S
        - AttributeName: timestamp
          AttributeType: S
      KeySchema:
        - AttributeName: device_id
          KeyType: HASH
        - AttributeName: timestamp
          KeyType: RANGE
      TimeToLiveSpecification:
        AttributeName: ttl
        Enabled: true
      StreamSpecification:
        StreamViewType: NEW_AND_OLD_IMAGES

  FirePredictionDeviceStateTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: FirePrediction-DeviceState
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: device_id
          AttributeType: S
      KeySchema:
        - AttributeName: device_id
          KeyType: HASH

  FirePredictionAlertsTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: FirePrediction-Alerts
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: device_id
          AttributeType: S
        - AttributeName: alert_timestamp
          AttributeType: S
      KeySchema:
        - AttributeName: device_id
          KeyType: HASH
        - AttributeName: alert_timestamp
          KeyType: RANGE
      TimeToLiveSpecification:
        AttributeName: ttl
        Enabled: true
```

### 1.4 DynamoDB 핸들러 구현

```python
from boto3.dynamodb.conditions import Key
from decimal import Decimal
import json

class DynamoDBHandler:
    def __init__(self):
        self.dynamodb = boto3.resource('dynamodb')
        self.raw_data_table = self.dynamodb.Table('FirePrediction-RawData')
        self.device_state_table = self.dynamodb.Table('FirePrediction-DeviceState')
        self.alerts_table = self.dynamodb.Table('FirePrediction-Alerts')
    
    def save_raw_data(self, processed_data):
        """원시 데이터 저장"""
        try:
            # TTL 설정 (30일 후 자동 삭제)
            ttl = int((datetime.now().timestamp() + (30 * 24 * 60 * 60)))
            
            # Decimal 변환 (DynamoDB 요구사항)
            item = self.convert_to_dynamodb_format({
                'device_id': str(processed_data['device_id']),
                'timestamp': processed_data['timestamp'],
                'ttl': ttl,
                'idx': processed_data['idx'],
                'status_bits': processed_data['status_bits'],
                'voltage': processed_data['voltage'],
                'voltage_low': processed_data['voltage_low'],
                'current': processed_data['current'],
                'leakage_current': processed_data['leakage_current'],
                'resistive_leakage': processed_data['resistive_leakage'],
                'power': processed_data['power'],
                'pcb_temperature': processed_data['pcb_temperature'],
                'sensor_temperature': processed_data['sensor_temperature'],
                'co_gas': processed_data['co_gas'],
                'voc': processed_data['voc'],
                'power_factor': processed_data['power_factor'],
                'arc_count': processed_data['arc_count'],
                'alarm_status': processed_data['alarm_status'],
                'risk_indicators': processed_data['risk_indicators']
            })
            
            self.raw_data_table.put_item(Item=item)
            return True
            
        except Exception as e:
            logger.error(f"DynamoDB save error: {e}")
            return False
    
    def convert_to_dynamodb_format(self, data):
        """Python 데이터를 DynamoDB 형식으로 변환"""
        if isinstance(data, dict):
            return {k: self.convert_to_dynamodb_format(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [self.convert_to_dynamodb_format(item) for item in data]
        elif isinstance(data, float):
            return Decimal(str(data))
        elif isinstance(data, int) and not isinstance(data, bool):
            return data
        else:
            return data
    
    def update_device_state(self, device_id, current_data, analysis_result):
        """디바이스 상태 업데이트"""
        try:
            response = self.device_state_table.update_item(
                Key={'device_id': str(device_id)},
                UpdateExpression="""
                    SET 
                        last_seen = :timestamp,
                        current_risk_level = :risk_level,
                        current_risk_score = :risk_score,
                        last_temperature = :temp,
                        last_arc_count = :arc,
                        total_alarms = if_not_exists(total_alarms, :zero) + :alarm_count,
                        last_status_bits = :status,
                        last_idx = :idx
                """,
                ExpressionAttributeValues={
                    ':timestamp': current_data['timestamp'],
                    ':risk_level': analysis_result.get('risk_level', 'UNKNOWN'),
                    ':risk_score': Decimal(str(analysis_result.get('risk_score', 0))),
                    ':temp': Decimal(str(max(current_data['pcb_temperature'], 
                                           current_data['sensor_temperature']))),
                    ':arc': current_data['arc_count'],
                    ':alarm_count': current_data['alarm_status']['total_alarm_count'],
                    ':status': current_data['status_bits'],
                    ':idx': current_data['idx'],
                    ':zero': 0
                },
                ReturnValues='ALL_NEW'
            )
            
            return response['Attributes']
            
        except Exception as e:
            logger.error(f"Device state update error: {e}")
            return None
    
    def get_device_history(self, device_id, hours=24):
        """디바이스 이력 조회"""
        try:
            from datetime import timedelta
            
            start_time = (datetime.now() - timedelta(hours=hours)).isoformat()
            
            response = self.raw_data_table.query(
                KeyConditionExpression=Key('device_id').eq(str(device_id)) & 
                                     Key('timestamp').gte(start_time),
                ScanIndexForward=False,  # 최신 순
                Limit=1000
            )
            
            return response['Items']
            
        except Exception as e:
            logger.error(f"History query error: {e}")
            return []
    
    def save_alert(self, device_id, alert_data):
        """알림 저장"""
        try:
            ttl = int((datetime.now().timestamp() + (90 * 24 * 60 * 60)))  # 90일
            
            item = self.convert_to_dynamodb_format({
                'device_id': str(device_id),
                'alert_timestamp': datetime.now().isoformat(),
                'ttl': ttl,
                'alert_level': alert_data['level'],
                'alert_type': alert_data['type'],
                'risk_score': alert_data['risk_score'],
                'message': alert_data['message'],
                'sensor_data': alert_data.get('sensor_data', {}),
                'resolved': False
            })
            
            self.alerts_table.put_item(Item=item)
            return True
            
        except Exception as e:
            logger.error(f"Alert save error: {e}")
            return False
```


# AWS IoT Core 화재 예측 시스템 - Part 2: Lambda 처리 및 실시간 분석

## 2. Lambda 함수를 통한 실시간 데이터 처리

### 2.1 메인 Lambda 핸들러

```python
import json
import boto3
import numpy as np
from datetime import datetime
import os
from sklearn.ensemble import IsolationForest
import joblib
import logging

logger = logging.getLogger()
logger.setLevel(logging.INFO)

def lambda_handler(event, context):
    """메인 Lambda 핸들러 - IoT Rule에서 트리거"""
    processor = DiscreteDataProcessor()
    analyzer = RealTimeAnalyzer(processor)
    
    try:
        # IoT 메시지 파싱
        iot_data = event if isinstance(event, dict) else json.loads(event)
        logger.info(f"Processing data for device: {iot_data.get('deviceId')}")
        
        # 데이터 처리
        processed_data = processor.parse_discrete_data(iot_data)
        if not processed_data:
            return {'statusCode': 400, 'body': 'Data processing failed'}
        
        # 데이터 유효성 검증
        validation = processor.validate_discrete_data(processed_data)
        if not validation['is_valid']:
            logger.warning(f"Invalid data: {validation['errors']}")
            # 유효하지 않은 데이터도 로깅을 위해 저장
        
        # DynamoDB에 원시 데이터 저장
        save_success = processor.dynamo_handler.save_raw_data(processed_data)
        if not save_success:
            logger.error("Failed to save raw data")
        
        # 실시간 분석
        analysis_result = analyzer.perform_realtime_analysis(processed_data)
        
        # 디바이스 상태 업데이트
        processor.dynamo_handler.update_device_state(
            processed_data['device_id'], 
            processed_data, 
            analysis_result
        )
        
        # Kinesis로 스트리밍 데이터 전송
        kinesis_success = processor.send_to_kinesis(processed_data, analysis_result)
        
        # 위험도에 따른 즉시 조치
        if analysis_result['risk_level'] in ['HIGH', 'CRITICAL']:
            processor.handle_high_risk_event(processed_data, analysis_result)
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'device_id': processed_data['device_id'],
                'risk_level': analysis_result['risk_level'],
                'risk_score': float(analysis_result['risk_score']),
                'validation': validation,
                'kinesis_sent': kinesis_success
            })
        }
        
    except Exception as e:
        logger.error(f"Lambda execution error: {e}")
        return {'statusCode': 500, 'body': f'Error: {str(e)}'}

class RealTimeAnalyzer:
    def __init__(self, processor):
        self.processor = processor
        self.dynamo_handler = processor.dynamo_handler
        
    def perform_realtime_analysis(self, data):
        """실시간 위험도 분석"""
        # 1. 기본 규칙 기반 분석
        rule_based_risk = self.rule_based_analysis(data)
        
        # 2. 디바이스 이력 기반 분석
        historical_context = self.get_historical_context(data['device_id'])
        
        # 3. 상태 비트 기반 분석
        status_risk = self.analyze_status_bits(data['alarm_status'])
        
        # 4. 센서 패턴 분석
        pattern_risk = self.analyze_sensor_patterns(data)
        
        # 종합 위험도 계산
        final_risk = self.calculate_final_risk(
            rule_based_risk, 
            historical_context, 
            status_risk, 
            pattern_risk
        )
        
        # 위험 수준 결정
        risk_level = self.determine_risk_level(final_risk)
        
        return {
            'risk_level': risk_level,
            'risk_score': final_risk,
            'rule_based_risk': rule_based_risk,
            'status_risk': status_risk,
            'pattern_risk': pattern_risk,
            'confidence': self.calculate_confidence(rule_based_risk, status_risk),
            'analysis_timestamp': datetime.now().isoformat()
        }
    
    def rule_based_analysis(self, data):
        """규칙 기반 위험도 분석 (Discrete 필드 기반)"""
        risk_score = 0
        
        # 온도 기반 위험도 (Discrete 주석: 60°C 기준)
        max_temp = max(data['pcb_temperature'], data['sensor_temperature'])
        if max_temp > 60:
            risk_score += 0.4
        elif max_temp > 50:
            risk_score += 0.3
        elif max_temp > 40:
            risk_score += 0.1
        
        # 전압 이상 (Discrete 주석: 234V 이상 고전압, 190V 이하 저전압)
        if data['voltage'] > 234 or data['voltage_low'] < 190:
            risk_score += 0.15
        
        # 전류 이상 (Discrete 주석: 100A 기준)
        if data['current'] > 100:
            risk_score += 0.2
        
        # 누전 (Discrete 주석: 8mA 기준)
        if data['leakage_current'] > 8 or data['resistive_leakage'] > 8:
            risk_score += 0.25
        
        # 아크 발생
        if data['arc_count'] > 0:
            risk_score += min(0.2, data['arc_count'] * 0.02)
        
        # 가스 농도 (Discrete 주석 기준)
        if data['co_gas'] > 17:  # 17ppm
            risk_score += 0.15
        if data['voc'] > 400:    # 400μg/m³
            risk_score += 0.1
        
        # 역률 이상 (Discrete 주석: 90% 기준)
        if data['power_factor'] < 0.9:
            risk_score += 0.05
        
        return min(1.0, risk_score)
    
    def analyze_status_bits(self, alarm_status):
        """상태 비트 기반 위험도 분석"""
        risk_score = 0
        
        # 각 알람별 가중치
        alarm_weights = {
            'overvoltage': 0.1,
            'power_outage': 0.15,
            'overcurrent': 0.2,
            'total_leakage': 0.25,
            'resistive_leakage': 0.2,
            'power_anomaly': 0.1,
            'pcb_temp_alarm': 0.3,
            'sensor_temp_alarm': 0.3,
            'co_alarm': 0.2,
            'voc_alarm': 0.15,
            'power_factor_alarm': 0.05,
            'arc_alarm': 0.25
        }
        
        for alarm, weight in alarm_weights.items():
            if alarm_status.get(alarm, False):
                risk_score += weight
        
        # 다중 알람 발생 시 추가 가중치
        if alarm_status['total_alarm_count'] > 2:
            risk_score += 0.1 * (alarm_status['total_alarm_count'] - 2)
        
        # 통신 오류 처리
        if alarm_status.get('communication_error', False):
            return 0.8  # 통신 오류는 별도 처리
        
        return min(1.0, risk_score)
    
    def analyze_sensor_patterns(self, data):
        """센서 데이터 패턴 분석"""
        pattern_risk = 0
        
        # 온도 불균형 (PCB와 센서 온도 차이)
        temp_diff = abs(data['pcb_temperature'] - data['sensor_temperature'])
        if temp_diff > 20:
            pattern_risk += 0.15
        elif temp_diff > 10:
            pattern_risk += 0.05
        
        # 전력 계산 및 이상 탐지
        calculated_power = data['voltage'] * data['current'] * data['power_factor']
        if abs(calculated_power - data['power']) > calculated_power * 0.2:
            pattern_risk += 0.1
        
        # 저항 계산 (옴의 법칙)
        if data['current'] > 0.1:  # 전류가 있을 때만
            resistance = data['voltage'] / data['current']
            if resistance < 1 or resistance > 1000:  # 비정상적인 저항값
                pattern_risk += 0.1
        
        return min(1.0, pattern_risk)
    
    def get_historical_context(self, device_id):
        """디바이스 이력 컨텍스트 분석"""
        try:
            # 최근 1시간 데이터 조회
            recent_data = self.dynamo_handler.get_device_history(device_id, hours=1)
            
            if len(recent_data) < 5:
                return {'trend': 'INSUFFICIENT_DATA', 'risk_modifier': 1.0}
            
            # 위험도 트렌드 분석
            risk_scores = []
            temperatures = []
            arc_counts = []
            
            for item in recent_data[:20]:  # 최근 20개 데이터
                if 'risk_indicators' in item:
                    risk_scores.append(float(item['risk_indicators']['total_risk_score']))
                temperatures.append(float(item['pcb_temperature']))
                arc_counts.append(int(item['arc_count']))
            
            context = {
                'recent_data_count': len(recent_data),
                'avg_temperature': np.mean(temperatures),
                'temp_trend': self.calculate_trend(temperatures),
                'total_arcs_hour': sum(arc_counts),
                'avg_risk_score': np.mean(risk_scores) if risk_scores else 0.5
            }
            
            # 위험도 수정자 계산
            risk_modifier = 1.0
            if context['temp_trend'] > 0.1:  # 온도 상승 트렌드
                risk_modifier += 0.2
            if context['total_arcs_hour'] > 10:  # 아크 빈발
                risk_modifier += 0.3
            if context['avg_risk_score'] > 0.6:  # 지속적 고위험
                risk_modifier += 0.1
            
            context['risk_modifier'] = min(2.0, risk_modifier)
            
            return context
            
        except Exception as e:
            logger.error(f"Historical context analysis error: {e}")
            return {'trend': 'ERROR', 'risk_modifier': 1.0}
    
    def calculate_trend(self, values):
        """선형 트렌드 계산"""
        if len(values) < 3:
            return 0
        
        # 단순 선형 회귀로 기울기 계산
        n = len(values)
        x = np.arange(n)
        
        slope = np.polyfit(x, values, 1)[0]
        return slope
    
    def calculate_final_risk(self, rule_risk, historical_context, status_risk, pattern_risk):
        """종합 위험도 계산"""
        # 기본 가중 평균
        base_risk = (
            rule_risk * 0.4 +
            status_risk * 0.3 +
            pattern_risk * 0.3
        )
        
        # 이력 컨텍스트 적용
        risk_modifier = historical_context.get('risk_modifier', 1.0)
        final_risk = base_risk * risk_modifier
        
        return min(1.0, final_risk)
    
    def determine_risk_level(self, risk_score):
        """위험 수준 결정"""
        if risk_score >= 0.8:
            return 'CRITICAL'
        elif risk_score >= 0.6:
            return 'HIGH'
        elif risk_score >= 0.4:
            return 'MEDIUM'
        elif risk_score >= 0.2:
            return 'LOW'
        else:
            return 'NORMAL'
    
    def calculate_confidence(self, rule_risk, status_risk):
        """예측 신뢰도 계산"""
        # 규칙 기반과 상태 기반 위험도의 일치도
        diff = abs(rule_risk - status_risk)
        confidence = 1.0 - (diff * 0.5)
        return max(0.5, min(1.0, confidence))

class AlertManager:
    def __init__(self):
        self.sns = boto3.client('sns')
        self.dynamo_handler = DynamoDBHandler()
        
    def handle_high_risk_event(self, data, analysis_result):
        """고위험 이벤트 처리"""
        try:
            device_id = data['device_id']
            risk_level = analysis_result['risk_level']
            risk_score = analysis_result['risk_score']
            
            # 알림 데이터 구성
            alert_data = {
                'level': risk_level,
                'type': self.determine_alert_type(data, analysis_result),
                'risk_score': risk_score,
                'message': self.generate_alert_message(data, analysis_result),
                'sensor_data': {
                    'temperature': max(data['pcb_temperature'], data['sensor_temperature']),
                    'voltage': data['voltage'],
                    'current': data['current'],
                    'arc_count': data['arc_count'],
                    'co_gas': data['co_gas'],
                    'voc': data['voc']
                },
                'recommendations': self.generate_recommendations(data, analysis_result)
            }
            
            # 알림 저장
            self.dynamo_handler.save_alert(device_id, alert_data)
            
            # SNS 알림 발송
            if risk_level == 'CRITICAL':
                self.send_critical_alert(device_id, alert_data)
            elif risk_level == 'HIGH':
                self.send_high_risk_alert(device_id, alert_data)
            
            return True
            
        except Exception as e:
            logger.error(f"Alert handling error: {e}")
            return False
    
    def determine_alert_type(self, data, analysis_result):
        """알림 유형 결정"""
        alarm_status = data['alarm_status']
        
        if alarm_status['pcb_temp_alarm'] or alarm_status['sensor_temp_alarm']:
            return 'TEMPERATURE_CRITICAL'
        elif alarm_status['arc_alarm'] or data['arc_count'] > 0:
            return 'ARC_DETECTED'
        elif alarm_status['total_leakage'] or alarm_status['resistive_leakage']:
            return 'ELECTRICAL_LEAKAGE'
        elif alarm_status['overcurrent']:
            return 'OVERCURRENT'
        elif alarm_status['co_alarm'] or alarm_status['voc_alarm']:
            return 'GAS_DETECTION'
        else:
            return 'GENERAL_RISK'
    
    def generate_alert_message(self, data, analysis_result):
        """알림 메시지 생성"""
        device_id = data['device_id']
        risk_level = analysis_result['risk_level']
        risk_score = analysis_result['risk_score']
        
        message = f"🚨 화재 위험 감지 - 디바이스 {device_id}\n"
        message += f"위험도: {risk_level} ({risk_score:.2f})\n"
        message += f"시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        
        # 주요 위험 요소
        if data['alarm_status']['pcb_temp_alarm'] or data['alarm_status']['sensor_temp_alarm']:
            max_temp = max(data['pcb_temperature'], data['sensor_temperature'])
            message += f"⚠️ 고온 감지: {max_temp:.1f}°C\n"
        
        if data['arc_count'] > 0:
            message += f"⚡ 아크 발생: {data['arc_count']}회\n"
        
        if data['alarm_status']['total_leakage']:
            message += f"💧 누전 감지: {data['leakage_current']:.1f}mA\n"
        
        if data['co_gas'] > 17:
            message += f"☁️ CO 가스: {data['co_gas']:.1f}ppm\n"
        
        if data['voc'] > 400:
            message += f"🌫️ VOC: {data['voc']:.1f}μg/m³\n"
        
        return message
    
    def generate_recommendations(self, data, analysis_result):
        """권장 조치사항 생성"""
        recommendations = []
        
        if data['alarm_status']['pcb_temp_alarm'] or data['alarm_status']['sensor_temp_alarm']:
            recommendations.append("즉시 냉각 조치 및 환기 확인")
            recommendations.append("전원 차단 검토")
        
        if data['arc_count'] > 0:
            recommendations.append("배선 연결부 점검")
            recommendations.append("절연체 상태 확인")
        
        if data['alarm_status']['total_leakage']:
            recommendations.append("누전 차단기 작동 확인")
            recommendations.append("접지 상태 점검")
        
        if data['co_gas'] > 17 or data['voc'] > 400:
            recommendations.append("즉시 환기 실시")
            recommendations.append("가스 누출원 확인")
        
        if analysis_result['risk_level'] == 'CRITICAL':
            recommendations.append("🚨 즉시 현장 점검 필요")
            recommendations.append("필요시 전원 차단 고려")
        
        return recommendations
    
    def send_critical_alert(self, device_id, alert_data):
        """긴급 알림 발송"""
        try:
            topic_arn = os.environ.get('CRITICAL_ALERT_TOPIC_ARN')
            if not topic_arn:
                logger.warning("Critical alert topic ARN not configured")
                return
            
            message = {
                'default': alert_data['message'],
                'sms': f"🚨긴급🚨 화재위험 디바이스{device_id} 위험도:{alert_data['risk_score']:.2f}",
                'email': self.format_email_alert(device_id, alert_data)
            }
            
            self.sns.publish(
                TopicArn=topic_arn,
                Message=json.dumps(message),
                MessageStructure='json',
                Subject=f"🚨 CRITICAL: 화재 위험 감지 - 디바이스 {device_id}"
            )
            
        except Exception as e:
            logger.error(f"Critical alert send error: {e}")
    
    def send_high_risk_alert(self, device_id, alert_data):
        """고위험 알림 발송"""
        try:
            topic_arn = os.environ.get('HIGH_RISK_ALERT_TOPIC_ARN')
            if not topic_arn:
                logger.warning("High risk alert topic ARN not configured")
                return
            
            self.sns.publish(
                TopicArn=topic_arn,
                Message=alert_data['message'],
                Subject=f"⚠️ HIGH RISK: 화재 위험 증가 - 디바이스 {device_id}"
            )
            
        except Exception as e:
            logger.error(f"High risk alert send error: {e}")
    
    def format_email_alert(self, device_id, alert_data):
        """이메일 알림 포맷"""
        html_content = f"""
        <html>
        <body>
            <h2 style="color: red;">🚨 화재 위험 감지 알림</h2>
            <p><strong>디바이스 ID:</strong> {device_id}</p>
            <p><strong>위험 수준:</strong> {alert_data['level']}</p>
            <p><strong>위험 점수:</strong> {alert_data['risk_score']:.2f}</p>
            <p><strong>감지 시간:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            
            <h3>센서 데이터</h3>
            <ul>
                <li>온도: {alert_data['sensor_data']['temperature']:.1f}°C</li>
                <li>전압: {alert_data['sensor_data']['voltage']:.1f}V</li>
                <li>전류: {alert_data['sensor_data']['current']:.1f}A</li>
                <li>아크 횟수: {alert_data['sensor_data']['arc_count']}</li>
                <li>CO 가스: {alert_data['sensor_data']['co_gas']:.1f}ppm</li>
                <li>VOC: {alert_data['sensor_data']['voc']:.1f}μg/m³</li>
            </ul>
            
            <h3>권장 조치사항</h3>
            <ul>
        """
        
        for recommendation in alert_data['recommendations']:
            html_content += f"<li>{recommendation}</li>"
        
        html_content += """
            </ul>
            <p style="color: red; font-weight: bold;">
                긴급한 조치가 필요할 수 있습니다. 즉시 현장을 확인하시기 바랍니다.
            </p>
        </body>
        </html>
        """
        
        return html_content

# DiscreteDataProcessor에 추가 메서드들
class DiscreteDataProcessor:
    def __init__(self):
        self.dynamodb = boto3.resource('dynamodb')
        self.kinesis = boto3.client('kinesis')
        self.sns = boto3.client('sns')
        
        # 핸들러들
        self.dynamo_handler = DynamoDBHandler()
        self.alert_manager = AlertManager()
        
        # Kinesis 스트림명
        self.stream_name = os.environ.get('KINESIS_STREAM_NAME', 'fire-prediction-stream')
    
    def send_to_kinesis(self, processed_data, analysis_result):
        """Kinesis로 데이터 전송"""
        try:
            record = {
                'device_id': processed_data['device_id'],
                'timestamp': processed_data['timestamp'],
                'sensor_data': {
                    'voltage': processed_data['voltage'],
                    'current': processed_data['current'],
                    'temperature': max(processed_data['pcb_temperature'], 
                                     processed_data['sensor_temperature']),
                    'leakage_current': processed_data['leakage_current'],
                    'co_gas': processed_data['co_gas'],
                    'voc': processed_data['voc'],
                    'power_factor': processed_data['power_factor'],
                    'arc_count': processed_data['arc_count']
                },
                'risk_analysis': analysis_result,
                'alarm_status': processed_data['alarm_status'],
                'discrete_idx': processed_data['idx']
            }
            
            response = self.kinesis.put_record(
                StreamName=self.stream_name,
                Data=json.dumps(record, default=str),
                PartitionKey=str(processed_data['device_id'])
            )
            
            logger.info(f"Data sent to Kinesis: {response['SequenceNumber']}")
            return True
            
        except Exception as e:
            logger.error(f"Kinesis send error: {e}")
            return False
    
    def handle_high_risk_event(self, processed_data, analysis_result):
        """고위험 이벤트 처리"""
        return self.alert_manager.handle_high_risk_event(processed_data, analysis_result)

# AWS IoT Core 화재 예측 시스템 - Part 3: Kinesis 스트림 처리 및 고급 분석

## 3. Amazon Kinesis를 통한 실시간 스트림 처리

### 3.1 Kinesis Data Streams 설정

```yaml
# CloudFormation 템플릿
Resources:
  FirePredictionKinesisStream:
    Type: AWS::Kinesis::Stream
    Properties:
      Name: fire-prediction-stream
      ShardCount: 2
      RetentionPeriodHours: 24
      
  KinesisAnalyticsApplication:
    Type: AWS::KinesisAnalytics::Application
    Properties:
      ApplicationName: fire-prediction-analytics
      ApplicationDescription: "Real-time fire risk analytics"
      Inputs:
        - NamePrefix: "SOURCE_SQL_STREAM"
          KinesisStreamsInput:
            ResourceARN: !GetAtt FirePredictionKinesisStream.Arn
            RoleARN: !GetAtt KinesisAnalyticsRole.Arn
          InputSchema:
            RecordColumns:
              - Name: device_id
                SqlType: VARCHAR(32)
                Mapping: $.device_id
              - Name: timestamp
                SqlType: TIMESTAMP
                Mapping: $.timestamp
              - Name: temperature
                SqlType: DOUBLE
                Mapping: $.sensor_data.temperature
              - Name: current
                SqlType: DOUBLE
                Mapping: $.sensor_data.current
              - Name: voltage
                SqlType: DOUBLE
                Mapping: $.sensor_data.voltage
              - Name: arc_count
                SqlType: INTEGER
                Mapping: $.sensor_data.arc_count
              - Name: risk_score
                SqlType: DOUBLE
                Mapping: $.risk_analysis.risk_score
            RecordFormat:
              RecordFormatType: JSON
```

### 3.2 Kinesis Data Processor Lambda

```python
import boto3
import json
from datetime import datetime, timedelta
import base64
import numpy as np
from collections import defaultdict
import logging

logger = logging.getLogger()
logger.setLevel(logging.INFO)

class KinesisDataProcessor:
    def __init__(self):
        self.sns = boto3.client('sns')
        self.cloudwatch = boto3.client('cloudwatch')
        self.dynamodb = boto3.resource('dynamodb')
        self.predictions_table = self.dynamodb.Table('FirePrediction-Predictions')
        self.s3 = boto3.client('s3')
        
        # 집계용 임시 스토리지
        self.batch_aggregations = defaultdict(list)
        
    def lambda_handler(self, event, context):
        """Kinesis 트리거 Lambda 함수"""
        try:
            processed_records = 0
            high_risk_devices = []
            device_aggregations = defaultdict(list)
            
            # 배치 레코드 처리
            for record in event['Records']:
                # Kinesis 레코드 디코딩
                payload = json.loads(base64.b64decode(record['kinesis']['data']))
                
                # 데이터 처리
                result = self.process_kinesis_record(payload)
                device_aggregations[payload['device_id']].append(result)
                
                if result['action_required']:
                    high_risk_devices.append(result)
                
                processed_records += 1
            
            # 디바이스별 배치 분석
            batch_analysis_results = self.perform_batch_analysis(device_aggregations)
            
            # 배치 처리 결과 로깅
            self.log_batch_metrics(processed_records, len(high_risk_devices))
            
            # 고위험 디바이스에 대한 추가 조치
            if high_risk_devices:
                self.handle_high_risk_batch(high_risk_devices)
            
            # S3에 배치 데이터 저장 (분석용)
            self.save_batch_to_s3(device_aggregations, batch_analysis_results)
            
            return {
                'statusCode': 200,
                'processed_records': processed_records,
                'high_risk_count': len(high_risk_devices),
                'batch_analysis': batch_analysis_results
            }
            
        except Exception as e:
            logger.error(f"Kinesis processing error: {e}")
            return {'statusCode': 500, 'error': str(e)}
    
    def process_kinesis_record(self, payload):
        """개별 Kinesis 레코드 처리"""
        device_id = payload['device_id']
        risk_score = payload['risk_analysis']['risk_score']
        timestamp = payload['timestamp']
        
        # 시계열 패턴 분석
        pattern_analysis = self.analyze_temporal_patterns(device_id, payload)
        
        # 센서 데이터 이상치 탐지
        anomaly_analysis = self.detect_sensor_anomalies(payload['sensor_data'])
        
        # 디바이스 간 상관관계 분석
        correlation_analysis = self.analyze_device_correlation(device_id, payload)
        
        # 예측 결과 구성
        prediction_result = {
            'device_id': device_id,
            'timestamp': timestamp,
            'risk_score': risk_score,
            'pattern_analysis': pattern_analysis,
            'anomaly_analysis': anomaly_analysis,
            'correlation_analysis': correlation_analysis,
            'sensor_summary': self.summarize_sensor_data(payload['sensor_data']),
            'prediction_confidence': self.calculate_prediction_confidence(payload)
        }
        
        # 예측 결과 저장
        self.save_prediction_result(prediction_result)
        
        # CloudWatch 메트릭 전송
        self.send_cloudwatch_metrics(device_id, payload)
        
        # 액션 필요 여부 결정
        action_required = self.determine_action_required(
            risk_score, 
            pattern_analysis, 
            anomaly_analysis,
            payload['alarm_status']
        )
        
        return {
            'device_id': device_id,
            'risk_score': risk_score,
            'action_required': action_required,
            'prediction_result': prediction_result,
            'raw_payload': payload
        }
    
    def analyze_temporal_patterns(self, device_id, current_payload):
        """시계열 패턴 분석"""
        try:
            # Redis나 DynamoDB에서 최근 데이터 조회 (실제 구현에서는 캐시 사용)
            historical_data = self.get_recent_kinesis_data(device_id, minutes=60)
            
            if len(historical_data) < 10:
                return {'trend': 'INSUFFICIENT_DATA', 'pattern': 'UNKNOWN'}
            
            # 온도 트렌드 분석
            temperatures = [data['sensor_data']['temperature'] for data in historical_data]
            temp_trend = self.calculate_trend(temperatures)
            temp_velocity = self.calculate_velocity(temperatures)
            
            # 위험도 트렌드 분석
            risk_scores = [data['risk_analysis']['risk_score'] for data in historical_data]
            risk_trend = self.calculate_trend(risk_scores)
            
            # 아크 발생 패턴
            arc_counts = [data['sensor_data']['arc_count'] for data in historical_data]
            arc_pattern = self.analyze_arc_pattern(arc_counts)
            
            # 주기성 분석 (FFT 기반)
            periodicity = self.detect_periodicity(temperatures)
            
            return {
                'temperature_trend': temp_trend,
                'temperature_velocity': temp_velocity,
                'risk_trend': risk_trend,
                'arc_pattern': arc_pattern,
                'trend': self.determine_overall_trend(temp_trend, risk_trend),
                'periodicity': periodicity,
                'data_points': len(historical_data),
                'trend_confidence': self.calculate_trend_confidence(temperatures, risk_scores)
            }
            
        except Exception as e:
            logger.error(f"Pattern analysis error: {e}")
            return {'trend': 'ERROR', 'pattern': 'UNKNOWN'}
    
    def detect_sensor_anomalies(self, sensor_data):
        """센서 데이터 이상치 탐지"""
        anomalies = []
        
        # 통계적 이상치 탐지 (Z-score 기반)
        z_scores = {}
        
        # 각 센서별 기준값 (정상 범위)
        normal_ranges = {
            'temperature': (20, 60),
            'voltage': (200, 250),
            'current': (0, 120),
            'co_gas': (0, 20),
            'voc': (0, 500),
            'power_factor': (0.8, 1.0)
        }
        
        for sensor, (min_val, max_val) in normal_ranges.items():
            if sensor in sensor_data:
                value = sensor_data[sensor]
                
                # 범위 초과 검사
                if value < min_val or value > max_val:
                    anomalies.append({
                        'sensor': sensor,
                        'value': value,
                        'type': 'RANGE_VIOLATION',
                        'severity': 'HIGH' if sensor == 'temperature' else 'MEDIUM'
                    })
        
        # 센서 간 일관성 검사
        consistency_check = self.check_sensor_consistency(sensor_data)
        if not consistency_check['consistent']:
            anomalies.extend(consistency_check['anomalies'])
        
        return {
            'anomalies': anomalies,
            'anomaly_count': len(anomalies),
            'severity_distribution': self.count_anomaly_severity(anomalies)
        }
    
    def check_sensor_consistency(self, sensor_data):
        """센서 간 일관성 검사"""
        anomalies = []
        
        # 전력 일관성 검사 (P = V * I * PF)
        if all(k in sensor_data for k in ['voltage', 'current', 'power_factor']):
            calculated_power = (sensor_data['voltage'] * 
                              sensor_data['current'] * 
                              sensor_data['power_factor'])
            
            # 실제 전력값이 있다면 비교
            if 'power' in sensor_data:
                power_diff = abs(calculated_power - sensor_data['power'])
                if power_diff > calculated_power * 0.2:  # 20% 이상 차이
                    anomalies.append({
                        'sensor': 'power_consistency',
                        'type': 'CALCULATION_MISMATCH',
                        'calculated': calculated_power,
                        'measured': sensor_data['power'],
                        'difference': power_diff,
                        'severity': 'MEDIUM'
                    })
        
        # 온도 센서 일관성 (PCB vs 센서)
        # 실제 구현에서는 payload에 두 온도값이 모두 있다고 가정
        
        return {
            'consistent': len(anomalies) == 0,
            'anomalies': anomalies
        }
    
    def analyze_device_correlation(self, device_id, payload):
        """디바이스 간 상관관계 분석"""
        try:
            # 동일 지역/건물의 다른 디바이스 데이터 조회
            nearby_devices = self.get_nearby_devices_data(device_id)
            
            if not nearby_devices:
                return {'correlation': 'NO_NEARBY_DEVICES'}
            
            correlations = {}
            current_temp = payload['sensor_data']['temperature']
            current_risk = payload['risk_analysis']['risk_score']
            
            for other_device in nearby_devices:
                # 온도 상관관계
                temp_correlation = self.calculate_correlation(
                    current_temp, 
                    other_device['temperature']
                )
                
                # 위험도 상관관계
                risk_correlation = self.calculate_correlation(
                    current_risk,
                    other_device['risk_score']
                )
                
                correlations[other_device['device_id']] = {
                    'temperature_correlation': temp_correlation,
                    'risk_correlation': risk_correlation,
                    'distance': other_device.get('distance', 'unknown')
                }
            
            # 클러스터 위험도 분석
            cluster_risk = self.analyze_cluster_risk(device_id, nearby_devices, payload)
            
            return {
                'correlations': correlations,
                'cluster_risk': cluster_risk,
                'nearby_device_count': len(nearby_devices)
            }
            
        except Exception as e:
            logger.error(f"Correlation analysis error: {e}")
            return {'correlation': 'ERROR'}
    
    def perform_batch_analysis(self, device_aggregations):
        """배치 분석 수행"""
        batch_results = {}
        
        for device_id, records in device_aggregations.items():
            if len(records) < 2:
                continue
            
            # 배치 내 트렌드 분석
            risk_scores = [r['risk_score'] for r in records]
            trend_analysis = {
                'risk_trend': self.calculate_trend(risk_scores),
                'risk_volatility': np.std(risk_scores),
                'max_risk': max(risk_scores),
                'min_risk': min(risk_scores),
                'avg_risk': np.mean(risk_scores)
            }
            
            # 배치 내 이상치 탐지
            batch_anomalies = self.detect_batch_anomalies(records)
            
            # 배치 추천사항
            recommendations = self.generate_batch_recommendations(
                device_id, 
                trend_analysis, 
                batch_anomalies
            )
            
            batch_results[device_id] = {
                'trend_analysis': trend_analysis,
                'batch_anomalies': batch_anomalies,
                'recommendations': recommendations,
                'record_count': len(records)
            }
        
        return batch_results
    
    def detect_batch_anomalies(self, records):
        """배치 내 이상치 탐지"""
        anomalies = []
        
        # 급격한 위험도 변화 탐지
        risk_scores = [r['risk_score'] for r in records]
        for i in range(1, len(risk_scores)):
            risk_change = abs(risk_scores[i] - risk_scores[i-1])
            if risk_change > 0.3:  # 30% 이상 급변
                anomalies.append({
                    'type': 'RAPID_RISK_CHANGE',
                    'change': risk_change,
                    'timestamp': records[i]['prediction_result']['timestamp']
                })
        
        # 지속적인 고위험 상태
        high_risk_streak = 0
        for record in records:
            if record['risk_score'] > 0.7:
                high_risk_streak += 1
            else:
                high_risk_streak = 0
        
        if high_risk_streak >= 3:
            anomalies.append({
                'type': 'SUSTAINED_HIGH_RISK',
                'streak_length': high_risk_streak
            })
        
        return anomalies
    
    def save_batch_to_s3(self, device_aggregations, batch_analysis_results):
        """배치 데이터를 S3에 저장 (분석용)"""
        try:
            bucket_name = os.environ.get('ANALYTICS_BUCKET')
            if not bucket_name:
                return
            
            # 파일명 생성 (파티션 기반)
            now = datetime.now()
            s3_key = f"kinesis-batch/{now.year}/{now.month:02d}/{now.day:02d}/{now.hour:02d}/{now.minute:02d}-batch.json"
            
            batch_data = {
                'timestamp': now.isoformat(),
                'device_aggregations': device_aggregations,
                'batch_analysis': batch_analysis_results,
                'record_count': sum(len(records) for records in device_aggregations.values())
            }
            
            self.s3.put_object(
                Bucket=bucket_name,
                Key=s3_key,
                Body=json.dumps(batch_data, default=str),
                ContentType='application/json'
            )
            
        except Exception as e:
            logger.error(f"S3 save error: {e}")
    
    def calculate_trend(self, values):
        """선형 트렌드 계산"""
        if len(values) < 3:
            return 0
        
        n = len(values)
        x = np.arange(n)
        slope = np.polyfit(x, values, 1)[0]
        return slope
    
    def calculate_velocity(self, values):
        """변화 속도 계산 (1차 미분)"""
        if len(values) < 2:
            return 0
        
        velocities = np.diff(values)
        return np.mean(velocities)
    
    def analyze_arc_pattern(self, arc_counts):
        """아크 발생 패턴 분석"""
        total_arcs = sum(arc_counts)
        non_zero_count = sum(1 for count in arc_counts if count > 0)
        
        if total_arcs == 0:
            return {'pattern': 'NO_ARCS', 'frequency': 0}
        
        frequency = non_zero_count / len(arc_counts)
        
        if frequency > 0.5:
            pattern = 'FREQUENT'
        elif frequency > 0.2:
            pattern = 'MODERATE'
        else:
            pattern = 'SPORADIC'
        
        return {
            'pattern': pattern,
            'frequency': frequency,
            'total_arcs': total_arcs,
            'max_single_event': max(arc_counts)
        }
    
    def detect_periodicity(self, values):
        """주기성 탐지 (FFT 기반)"""
        if len(values) < 10:
            return {'periodic': False}
        
        try:
            # FFT 계산
            fft_values = np.fft.fft(values)
            frequencies = np.fft.fftfreq(len(values))
            
            # 주요 주파수 성분 찾기
            magnitudes = np.abs(fft_values)
            dominant_freq_idx = np.argmax(magnitudes[1:]) + 1  # DC 성분 제외
            
            dominant_frequency = frequencies[dominant_freq_idx]
            period = 1 / abs(dominant_frequency) if dominant_frequency != 0 else None
            
            return {
                'periodic': magnitudes[dominant_freq_idx] > np.mean(magnitudes) * 2,
                'period': period,
                'dominant_frequency': dominant_frequency
            }
            
        except Exception as e:
            logger.error(f"Periodicity detection error: {e}")
            return {'periodic': False}
    
    def send_cloudwatch_metrics(self, device_id, payload):
        """CloudWatch 메트릭 전송"""
        try:
            metrics = []
            
            # 기본 메트릭
            base_metrics = [
                ('DeviceRiskScore', payload['risk_analysis']['risk_score']),
                ('DeviceTemperature', payload['sensor_data']['temperature']),
                ('DeviceCurrent', payload['sensor_data']['current']),
                ('DeviceVoltage', payload['sensor_data']['voltage']),
                ('DeviceArcCount', payload['sensor_data']['arc_count']),
                ('DeviceCOGas', payload['sensor_data']['co_gas']),
                ('DeviceVOC', payload['sensor_data']['voc'])
            ]
            
            for metric_name, value in base_metrics:
                metrics.append({
                    'MetricName': metric_name,
                    'Dimensions': [
                        {'Name': 'DeviceId', 'Value': str(device_id)}
                    ],
                    'Value': float(value),
                    'Unit': 'None',
                    'Timestamp': datetime.now()
                })
            
            # 알람 상태 메트릭
            alarm_count = payload['alarm_status']['total_alarm_count']
            metrics.append({
                'MetricName': 'DeviceAlarmCount',
                'Dimensions': [
                    {'Name': 'DeviceId', 'Value': str(device_id)}
                ],
                'Value': alarm_count,
                'Unit': 'Count',
                'Timestamp': datetime.now()
            })
            
            # 배치로 메트릭 전송
            for i in range(0, len(metrics), 20):  # CloudWatch 제한: 20개씩
                batch = metrics[i:i+20]
                self.cloudwatch.put_metric_data(
                    Namespace='FirePrediction/Devices',
                    MetricData=batch
                )
            
        except Exception as e:
            logger.error(f"CloudWatch metrics error: {e}")
    
    def save_prediction_result(self, prediction_result):
        """예측 결과 저장"""
        try:
            # TTL 설정 (7일)
            ttl = int((datetime.now().timestamp() + (7 * 24 * 60 * 60)))
            
            item = {
                'device_id': prediction_result['device_id'],
                'timestamp': prediction_result['timestamp'],
                'ttl': ttl,
                'risk_score': Decimal(str(prediction_result['risk_score'])),
                'pattern_analysis': prediction_result['pattern_analysis'],
                'anomaly_analysis': prediction_result['anomaly_analysis'],
                'correlation_analysis': prediction_result['correlation_analysis'],
                'sensor_summary': prediction_result['sensor_summary'],
                'prediction_confidence': Decimal(str(prediction_result['prediction_confidence']))
            }
            
            # Decimal 변환
            item = self.convert_to_dynamodb_format(item)
            
            self.predictions_table.put_item(Item=item)
            
        except Exception as e:
            logger.error(f"Prediction save error: {e}")
    
    def convert_to_dynamodb_format(self, data):
        """DynamoDB 형식 변환"""
        from decimal import Decimal
        
        if isinstance(data, dict):
            return {k: self.convert_to_dynamodb_format(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [self.convert_to_dynamodb_format(item) for item in data]
        elif isinstance(data, float):
            return Decimal(str(data))
        elif isinstance(data, int) and not isinstance(data, bool):
            return data
        else:
            return data

class KinesisAnalyticsQueries:
    """Kinesis Data Analytics SQL 쿼리들"""
    
    # 5분 윈도우 집계
    FIVE_MINUTE_AGGREGATION = """
    CREATE OR REPLACE STREAM "DEVICE_5MIN_AGGREGATES" AS
    SELECT 
        device_id,
        AVG(temperature) as avg_temperature,
        MAX(temperature) as max_temperature,
        MIN(temperature) as min_temperature,
        STDDEV_SAMP(temperature) as temp_stddev,
        AVG(risk_score) as avg_risk_score,
        MAX(risk_score) as max_risk_score,
        SUM(arc_count) as total_arcs,
        AVG(current) as avg_current,
        MAX(current) as max_current,
        COUNT(*) as record_count,
        ROWTIME_TO_TIMESTAMP(ROWTIME) as window_end
    FROM SOURCE_SQL_STREAM_001
    GROUP BY device_id, ROWTIME RANGE INTERVAL '5' MINUTE;
    """
    
    # 온도 이상치 탐지
    TEMPERATURE_ANOMALY_DETECTION = """
    CREATE OR REPLACE STREAM "TEMPERATURE_ANOMALIES" AS
    SELECT 
        device_id,
        temperature,
        risk_score,
        ROWTIME_TO_TIMESTAMP(ROWTIME) as detection_time,
        'TEMPERATURE_SPIKE' as anomaly_type
    FROM SOURCE_SQL_STREAM_001
    WHERE temperature > (
        SELECT AVG(temperature) + 2 * STDDEV_SAMP(temperature)
        FROM SOURCE_SQL_STREAM_001 
        WHERE device_id = s.device_id
        GROUP BY device_id, ROWTIME RANGE INTERVAL '1' HOUR
    ) AND temperature > 50;
    """
    
    # 위험도 급증 탐지
    RISK_SPIKE_DETECTION = """
    CREATE OR REPLACE STREAM "RISK_SPIKES" AS
    SELECT 
        device_id,
        risk_score,
        LAG(risk_score, 1) OVER (
            PARTITION BY device_id 
            ORDER BY ROWTIME RANGE INTERVAL '10' MINUTE
        ) as prev_risk_score,
        risk_score - LAG(risk_score, 1) OVER (
            PARTITION BY device_id 
            ORDER BY ROWTIME RANGE INTERVAL '10' MINUTE
        ) as risk_change,
        ROWTIME_TO_TIMESTAMP(ROWTIME) as detection_time
    FROM SOURCE_SQL_STREAM_001
    WHERE risk_score - LAG(risk_score, 1) OVER (
        PARTITION BY device_id 
        ORDER BY ROWTIME RANGE INTERVAL '10' MINUTE
    ) > 0.3;
    """
    
    # 다중 디바이스 상관관계
    MULTI_DEVICE_CORRELATION = """
    CREATE OR REPLACE STREAM "DEVICE_CORRELATIONS" AS
    SELECT 
        d1.device_id as device1,
        d2.device_id as device2,
        ABS(d1.temperature - d2.temperature) as temp_diff,
        ABS(d1.risk_score - d2.risk_score) as risk_diff,
        (d1.risk_score + d2.risk_score) / 2 as avg_risk,
        CASE 
            WHEN d1.risk_score > 0.7 AND d2.risk_score > 0.7 THEN 'HIGH_RISK_CLUSTER'
            WHEN ABS(d1.temperature - d2.temperature) > 20 THEN 'TEMP_DIVERGENCE'
            ELSE 'NORMAL'
        END as correlation_type,
        ROWTIME_TO_TIMESTAMP(ROWTIME) as analysis_time
    FROM SOURCE_SQL_STREAM_001 d1
    JOIN SOURCE_SQL_STREAM_001 d2 WITHIN INTERVAL '2' MINUTE
    ON d1.device_id != d2.device_id
    WHERE d1.risk_score > 0.5 OR d2.risk_score > 0.5;
    """
    
    # 아크 패턴 분석
    ARC_PATTERN_ANALYSIS = """
    CREATE OR REPLACE STREAM "ARC_PATTERNS" AS
    SELECT 
        device_id,
        SUM(arc_count) as total_arcs_10min,
        COUNT(CASE WHEN arc_count > 0 THEN 1 END) as arc_events,
        MAX(arc_count) as max_single_arc,
        AVG(CASE WHEN arc_count > 0 THEN arc_count END) as avg_arc_per_event,
        CASE 
            WHEN SUM(arc_count) > 10 THEN 'HIGH_FREQUENCY'
            WHEN SUM(arc_count) > 5 THEN 'MODERATE'
            WHEN SUM(arc_count) > 0 THEN 'LOW'
            ELSE 'NONE'
        END as arc_pattern,
        ROWTIME_TO_TIMESTAMP(ROWTIME) as window_end
    FROM SOURCE_SQL_STREAM_001
    WHERE ROWTIME RANGE INTERVAL '10' MINUTE PRECEDING
    GROUP BY device_id, ROWTIME RANGE INTERVAL '10' MINUTE;
    """

class KinesisOutputProcessor:
    """Kinesis Analytics 출력 처리"""
    
    def __init__(self):
        self.sns = boto3.client('sns')
        self.lambda_client = boto3.client('lambda')
        
    def process_analytics_output(self, event, context):
        """Kinesis Analytics 출력 처리"""
        try:
            for record in event['Records']:
                data = json.loads(base64.b64decode(record['kinesis']['data']))
                
                # 출력 스트림별 처리
                if 'TEMPERATURE_ANOMALIES' in record['eventSourceARN']:
                    self.handle_temperature_anomaly(data)
                elif 'RISK_SPIKES' in record['eventSourceARN']:
                    self.handle_risk_spike(data)
                elif 'DEVICE_CORRELATIONS' in record['eventSourceARN']:
                    self.handle_device_correlation(data)
                elif 'ARC_PATTERNS' in record['eventSourceARN']:
                    self.handle_arc_pattern(data)
            
            return {'statusCode': 200}
            
        except Exception as e:
            logger.error(f"Analytics output processing error: {e}")
            return {'statusCode': 500}
    
    def handle_temperature_anomaly(self, data):
        """온도 이상치 처리"""
        if data['temperature'] > 65:  # 매우 높은 온도
            self.send_critical_temperature_alert(data)
    
    def handle_risk_spike(self, data):
        """위험도 급증 처리"""
        if data['risk_change'] > 0.5:  # 50% 이상 급증
            self.trigger_emergency_response(data)
    
    def handle_device_correlation(self, data):
        """디바이스 상관관계 처리"""
        if data['correlation_type'] == 'HIGH_RISK_CLUSTER':
            self.alert_cluster_risk(data)
    
    def handle_arc_pattern(self, data):
        """아크 패턴 처리"""
        if data['arc_pattern'] == 'HIGH_FREQUENCY':
            self.schedule_maintenance_check(data)
    
    def send_critical_temperature_alert(self, data):
        """긴급 온도 알림"""
        message = f"🌡️ 긴급: 디바이스 {data['device_id']} 고온 감지 - {data['temperature']:.1f}°C"
        
        self.sns.publish(
            TopicArn=os.environ.get('EMERGENCY_TOPIC_ARN'),
            Message=message,
            Subject="긴급: 고온 감지"
        )
    
    def trigger_emergency_response(self, data):
        """비상 대응 트리거"""
        # Lambda 함수 호출로 비상 프로토콜 실행
        self.lambda_client.invoke(
            FunctionName=os.environ.get('EMERGENCY_RESPONSE_FUNCTION'),
            InvocationType='Event',
            Payload=json.dumps({
                'device_id': data['device_id'],
                'risk_change': data['risk_change'],
                'current_risk': data['risk_score'],
                'trigger_time': data['detection_time']
            })
        )

# AWS IoT Core 화재 예측 시스템 - Part 4: SageMaker ML 파이프라인 및 고급 모델

## 4. Amazon SageMaker를 활용한 고급 ML 모델

### 4.1 SageMaker 학습 파이프라인

```python
import sagemaker
from sagemaker.tensorflow import TensorFlow
from sagemaker.processing import ProcessingInput, ProcessingOutput
from sagemaker.sklearn.processing import SKLearnProcessor
from sagemaker.workflow.pipeline import Pipeline
from sagemaker.workflow.steps import ProcessingStep, TrainingStep
from sagemaker.workflow.parameters import ParameterString, ParameterInteger
import pandas as pd
import numpy as np
import boto3

class SageMakerMLPipeline:
    def __init__(self):
        self.sagemaker_session = sagemaker.Session()
        self.role = sagemaker.get_execution_role()
        self.bucket = self.sagemaker_session.default_bucket()
        self.region = boto3.Session().region_name
        
    def create_preprocessing_script(self):
        """데이터 전처리 스크립트 생성"""
        preprocessing_code = 

'''
import argparse
import os
import boto3
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
import joblib
import json
from datetime import datetime, timedelta

def preprocess_discrete_data():
    """Discrete 데이터 전처리"""
    
    # DynamoDB에서 데이터 조회
    dynamodb = boto3.resource('dynamodb')
    raw_data_table = dynamodb.Table('FirePrediction-RawData')
    
    # 최근 30일 데이터 조회
    end_time = datetime.now()
    start_time = end_time - timedelta(days=30)
    
    # 데이터 수집
    all_data = []
    devices = get_all_device_ids()  # 모든 디바이스 ID 조회
    
    for device_id in devices:
        response = raw_data_table.query(
            KeyConditionExpression=Key('device_id').eq(device_id) & 
                                 Key('timestamp').between(
                                     start_time.isoformat(), 
                                     end_time.isoformat()
                                 )
        )
        all_data.extend(response['Items'])
    
    # DataFrame 변환
    df = pd.DataFrame(all_data)
    
    # Discrete 필드 기반 특징 추출
    features = extract_discrete_features(df)
    
    # 라벨 생성 (화재 발생 예측)
    labels = create_fire_labels(df)
    
    # 특징 엔지니어링
    engineered_features = engineer_features(features)
    
    # 데이터 분할
    X_train, X_test, y_train, y_test = train_test_split(
        engineered_features, labels, test_size=0.2, random_state=42, stratify=labels
    )
    
    # 정규화
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # 저장
    save_processed_data(X_train_scaled, X_test_scaled, y_train, y_test, scaler)

def extract_discrete_features(df):
    """Discrete 클래스 기반 특징 추출"""
    features = pd.DataFrame()
    
    # 기본 센서 데이터
    sensor_columns = [
        'voltage', 'voltage_low', 'current', 'leakage_current', 
        'resistive_leakage', 'power', 'pcb_temperature', 
        'sensor_temperature', 'co_gas', 'voc', 'power_factor', 'arc_count'
    ]
    
    for col in sensor_columns:
        if col in df.columns:
            features[col] = pd.to_numeric(df[col], errors='coerce')
    
    # 상태 비트 분해
    features = add_status_bit_features(features, df['status_bits'])
    
    # 시간 기반 특징
    features = add_temporal_features(features, df['timestamp'])
    
    return features

def add_status_bit_features(features, status_bits):
    """상태 비트를 개별 특징으로 분해"""
    # Discrete 클래스 주석 기반 비트 분해
    bit_names = [
        'overvoltage', 'power_outage', 'overcurrent', 'total_leakage',
        'resistive_leakage_alarm', 'power_anomaly', 'pcb_temp_alarm',
        'sensor_temp_alarm', 'co_alarm', 'voc_alarm', 'power_factor_alarm', 'arc_alarm'
    ]
    
    for i, bit_name in enumerate(bit_names):
        features[f'status_{bit_name}'] = status_bits.apply(lambda x: bool(x & (1 << i)))
    
    # 통신 오류
    features['communication_error'] = status_bits >= 4096
    
    # 총 알람 수
    features['total_alarms'] = status_bits.apply(
        lambda x: bin(x & 0xFFF).count('1') if x < 4096 else 0
    )
    
    return features

def add_temporal_features(features, timestamps):
    """시간 기반 특징 추가"""
    timestamps = pd.to_datetime(timestamps)
    
    features['hour'] = timestamps.dt.hour
    features['day_of_week'] = timestamps.dt.dayofweek
    features['month'] = timestamps.dt.month
    features['is_weekend'] = timestamps.dt.dayofweek.isin([5, 6])
    features['is_night'] = timestamps.dt.hour.isin([22, 23, 0, 1, 2, 3, 4, 5])
    
    return features

def engineer_features(features):
    """고급 특징 엔지니어링"""
    engineered = features.copy()
    
    # 온도 관련 특징
    engineered['max_temperature'] = features[['pcb_temperature', 'sensor_temperature']].max(axis=1)
    engineered['temp_difference'] = abs(features['pcb_temperature'] - features['sensor_temperature'])
    engineered['temp_ratio'] = features['pcb_temperature'] / (features['sensor_temperature'] + 1e-6)
    
    # 전기적 특징
    engineered['power_calculated'] = (features['voltage'] * features['current'] * 
                                    features['power_factor'])
    engineered['power_discrepancy'] = abs(engineered['power_calculated'] - features['power'])
    engineered['resistance'] = features['voltage'] / (features['current'] + 1e-6)
    engineered['current_density'] = features['current'] / (features['voltage'] + 1e-6)
    
    # 누전 관련 특징
    engineered['total_leakage'] = features['leakage_current'] + features['resistive_leakage']
    engineered['leakage_ratio'] = (features['resistive_leakage'] / 
                                 (features['leakage_current'] + 1e-6))
    
    # 가스 관련 특징
    engineered['gas_index'] = features['co_gas'] * 0.6 + features['voc'] * 0.4
    engineered['gas_risk_score'] = (
        (features['co_gas'] > 17).astype(int) * 0.7 +
        (features['voc'] > 400).astype(int) * 0.3
    )
    
    # 복합 위험 지표
    engineered['electrical_risk'] = (
        engineered['status_overcurrent'].astype(int) * 0.3 +
        engineered['status_total_leakage'].astype(int) * 0.4 +
        (engineered['arc_count'] > 0).astype(int) * 0.3
    )
    
    engineered['thermal_risk'] = (
        (engineered['max_temperature'] > 60).astype(int) * 0.6 +
        (engineered['temp_difference'] > 15).astype(int) * 0.4
    )
    
    return engineered

def create_fire_labels(df):
    """화재 라벨 생성"""
    # 실제 화재 발생 데이터가 있다면 사용
    # 여기서는 시뮬레이션된 라벨 생성
    
    fire_conditions = (
        (df['pcb_temperature'] > 70) |
        (df['sensor_temperature'] > 70) |
        (df['arc_count'] > 5) |
        ((df['co_gas'] > 25) & (df['voc'] > 600)) |
        (df['total_alarms'] > 4)
    )
    
    # 화재 발생 전 10분간도 양성으로 표시
    labels = fire_conditions.astype(int)
    
    # 시계열 확장 (향후 예측)
    for i in range(len(labels) - 10):
        if any(labels[i+1:i+11]):  # 향후 10분 내 화재 발생
            labels[i] = 1
    
    return labels

if __name__ == "__main__":
    preprocess_discrete_data()
'''
        
        # 전처리 스크립트를 S3에 저장
        with open('/tmp/preprocessing.py', 'w') as f:
            f.write(preprocessing_code)
        
        s3_client = boto3.client('s3')
        s3_client.upload_file(
            '/tmp/preprocessing.py',
            self.bucket,
            'scripts/preprocessing.py'
        )
        
        return f's3://{self.bucket}/scripts/preprocessing.py'
    
    def create_lstm_training_script(self):
        """LSTM 모델 학습 스크립트"""
        training_code = 
        
'''
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
import numpy as np
import pandas as pd
import argparse
import os
import joblib

def create_sequences(X, y, sequence_length=30):
    """시계열 시퀀스 생성"""
    sequences = []
    targets = []
    
    for i in range(len(X) - sequence_length):
        sequences.append(X[i:i+sequence_length])
        targets.append(y[i+sequence_length])
    
    return np.array(sequences), np.array(targets)

def build_advanced_lstm_model(input_shape):
    """고급 LSTM 모델 구축"""
    model = Sequential([
        # CNN 특징 추출 레이어
        Conv1D(64, 3, activation='relu', input_shape=input_shape),
        Conv1D(64, 3, activation='relu'),
        MaxPooling1D(2),
        Dropout(0.25),
        
        # LSTM 레이어들
        LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),
        LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),
        LSTM(32, dropout=0.2, recurrent_dropout=0.2),
        
        # Dense 레이어들
        Dense(64, activation='relu'),
        Dropout(0.5),
        Dense(32, activation='relu'),
        Dropout(0.3),
        Dense(16, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    
    # 커스텀 옵티마이저
    optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)
    
    model.compile(
        optimizer=optimizer,
        loss='binary_crossentropy',
        metrics=['accuracy', 'precision', 'recall', 'AUC']
    )
    
    return model

def train_model():
    """모델 학습 실행"""
    # 전처리된 데이터 로드
    X_train = np.load('/opt/ml/input/data/train/X_train.npy')
    X_test = np.load('/opt/ml/input/data/train/X_test.npy')
    y_train = np.load('/opt/ml/input/data/train/y_train.npy')
    y_test = np.load('/opt/ml/input/data/train/y_test.npy')
    
    # 시퀀스 생성
    sequence_length = 30
    X_train_seq, y_train_seq = create_sequences(X_train, y_train, sequence_length)
    X_test_seq, y_test_seq = create_sequences(X_test, y_test, sequence_length)
    
    # 모델 생성
    model = build_advanced_lstm_model((sequence_length, X_train.shape[1]))
    
    # 콜백 설정
    callbacks = [
        EarlyStopping(
            monitor='val_loss',
            patience=15,
            restore_best_weights=True,
            verbose=1
        ),
        ModelCheckpoint(
            '/opt/ml/model/best_model.h5',
            monitor='val_auc',
            save_best_only=True,
            mode='max',
            verbose=1
        ),
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=8,
            min_lr=1e-7,
            verbose=1
        )
    ]
    
    # 클래스 가중치 계산 (불균형 데이터 처리)
    class_weight = {
        0: 1.0,
        1: len(y_train_seq) / (2 * np.sum(y_train_seq))
    }
    
    # 모델 학습
    history = model.fit(
        X_train_seq, y_train_seq,
        epochs=100,
        batch_size=32,
        validation_data=(X_test_seq, y_test_seq),
        callbacks=callbacks,
        class_weight=class_weight,
        verbose=1
    )
    
    # 모델 저장
    model.save('/opt/ml/model/lstm_fire_prediction_model.h5')
    
    # 학습 이력 저장
    import pickle
    with open('/opt/ml/model/training_history.pkl', 'wb') as f:
        pickle.dump(history.history, f)
    
    # 모델 평가
    test_loss, test_accuracy, test_precision, test_recall, test_auc = model.evaluate(
        X_test_seq, y_test_seq, verbose=0
    )
    
    print(f"Test Results:")
    print(f"Loss: {test_loss:.4f}")
    print(f"Accuracy: {test_accuracy:.4f}")
    print(f"Precision: {test_precision:.4f}")
    print(f"Recall: {test_recall:.4f}")
    print(f"AUC: {test_auc:.4f}")

if __name__ == "__main__":
    train_model()
'''
        # 학습 스크립트를 S3에 저장
        with open('/tmp/train_lstm.py', 'w') as f:
            f.write(training_code)
        
        s3_client = boto3.client('s3')
        s3_client.upload_file(
            '/tmp/train_lstm.py',
            self.bucket,
            'scripts/train_lstm.py'
        )
        
        return f's3://{self.bucket}/scripts/train_lstm.py'

    def create_sagemaker_pipeline(self):
        """SageMaker 파이프라인 생성"""
        
        # 파라미터 정의
        processing_instance_type = ParameterString(
            name="ProcessingInstanceType",
            default_value="ml.m5.xlarge"
        )
        
        training_instance_type = ParameterString(
            name="TrainingInstanceType", 
            default_value="ml.p3.2xlarge"
        )
        
        model_approval_status = ParameterString(
            name="ModelApprovalStatus",
            default_value="PendingManualApproval"
        )
        
        # 전처리 스텝
        sklearn_processor = SKLearnProcessor(
            framework_version="0.23-1",
            instance_type=processing_instance_type,
            instance_count=1,
            base_job_name="fire-prediction-preprocessing",
            role=self.role,
        )
        
        preprocessing_step = ProcessingStep(
            name="PreprocessDiscreteData",
            processor=sklearn_processor,
            inputs=[
                ProcessingInput(
                    source=self.create_preprocessing_script(),
                    destination="/opt/ml/processing/input/code",
                    input_name="code"
                )
            ],
            outputs=[
                ProcessingOutput(
                    output_name="train",
                    source="/opt/ml/processing/output/train",
                    destination=f"s3://{self.bucket}/fire-prediction/train"
                ),
                ProcessingOutput(
                    output_name="test", 
                    source="/opt/ml/processing/output/test",
                    destination=f"s3://{self.bucket}/fire-prediction/test"
                )
            ],
            code=self.create_preprocessing_script()
        )
        
        # LSTM 학습 스텝
        tensorflow_estimator = TensorFlow(
            entry_point="train_lstm.py",
            source_dir=f"s3://{self.bucket}/scripts/",
            role=self.role,
            instance_count=1,
            instance_type=training_instance_type,
            framework_version="2.8",
            py_version="py39",
            script_mode=True,
            hyperparameters={
                'epochs': 100,
                'batch_size': 32,
                'learning_rate': 0.001
            }
        )
        
        training_step = TrainingStep(
            name="TrainLSTMModel",
            estimator=tensorflow_estimator,
            inputs={
                "train": TrainingInput(
                    s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[
                        "train"
                    ].S3Output.S3Uri,
                    content_type="application/x-npy"
                )
            }
        )
        
        # 파이프라인 정의
        pipeline = Pipeline(
            name="fire-prediction-pipeline",
            parameters=[
                processing_instance_type,
                training_instance_type,
                model_approval_status
            ],
            steps=[preprocessing_step, training_step],
            sagemaker_session=self.sagemaker_session
        )
        
        return pipeline

class RealTimeInferenceEndpoint:
    """실시간 추론 엔드포인트"""
    
    def __init__(self):
        self.sagemaker_client = boto3.client('sagemaker-runtime')
        self.endpoint_name = 'fire-prediction-lstm-endpoint'
        
    def create_inference_script(self):
        """추론 스크립트 생성"""
        inference_code = '''
import json
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
import joblib
import os

def model_fn(model_dir):
    """모델 로드"""
    model = load_model(os.path.join(model_dir, 'lstm_fire_prediction_model.h5'))
    scaler = joblib.load(os.path.join(model_dir, 'scaler.pkl'))
    return {'model': model, 'scaler': scaler}

def input_fn(request_body, content_type='application/json'):
    """입력 데이터 전처리"""
    if content_type == 'application/json':
        input_data = json.loads(request_body)
        
        # Discrete 데이터 형식 변환
        features = []
        
        # 기본 센서 데이터
        sensor_values = [
            input_data.get('voltage', 0),
            input_data.get('voltage_low', 0), 
            input_data.get('current', 0),
            input_data.get('leakage_current', 0),
            input_data.get('resistive_leakage', 0),
            input_data.get('power', 0),
            input_data.get('pcb_temperature', 0),
            input_data.get('sensor_temperature', 0),
            input_data.get('co_gas', 0),
            input_data.get('voc', 0),
            input_data.get('power_factor', 0),
            input_data.get('arc_count', 0)
        ]
        
        # 상태 비트 분해
        status_bits = input_data.get('status_bits', 0)
        status_features = []
        for i in range(12):
            status_features.append(int(bool(status_bits & (1 << i))))
        
        # 엔지니어드 특징 계산
        max_temp = max(sensor_values[6], sensor_values[7])  # pcb_temp, sensor_temp
        temp_diff = abs(sensor_values[6] - sensor_values[7])
        power_calc = sensor_values[0] * sensor_values[2] * sensor_values[10]  # V*I*PF
        
        engineered_features = [
            max_temp,
            temp_diff,
            power_calc,
            abs(power_calc - sensor_values[5]),  # power discrepancy
            sensor_values[0] / (sensor_values[2] + 1e-6),  # resistance
            sensor_values[3] + sensor_values[4],  # total leakage
            sensor_values[8] * 0.6 + sensor_values[9] * 0.4  # gas index
        ]
        
        # 전체 특징 벡터
        all_features = sensor_values + status_features + engineered_features
        
        return np.array(all_features).reshape(1, -1)
    
    else:
        raise ValueError(f"Unsupported content type: {content_type}")

def predict_fn(input_data, model_dict):
    """예측 수행"""
    model = model_dict['model']
    scaler = model_dict['scaler']
    
    # 데이터 정규화
    input_scaled = scaler.transform(input_data)
    
    # 시퀀스 형태로 변환 (단일 시점 예측을 위해 복제)
    sequence_length = 30
    input_sequence = np.repeat(input_scaled, sequence_length, axis=0)
    input_sequence = input_sequence.reshape(1, sequence_length, -1)
    
    # 예측
    prediction = model.predict(input_sequence)
    probability = float(prediction[0][0])
    
    # 위험 수준 결정
    if probability >= 0.8:
        risk_level = 'CRITICAL'
    elif probability >= 0.6:
        risk_level = 'HIGH'
    elif probability >= 0.4:
        risk_level = 'MEDIUM'
    elif probability >= 0.2:
        risk_level = 'LOW'
    else:
        risk_level = 'NORMAL'
    
    return {
        'fire_probability': probability,
        'risk_level': risk_level,
        'confidence': min(1.0, abs(probability - 0.5) * 2)  # 0.5에서 멀수록 높은 신뢰도
    }

def output_fn(prediction, accept='application/json'):
    """출력 형식 변환"""
    if accept == 'application/json':
        return json.dumps(prediction)
    else:
        raise ValueError(f"Unsupported accept type: {accept}")
'''
        
        return inference_code
    
    def deploy_model(self, model_artifacts_s3_path):
        """모델 배포"""
        from sagemaker.tensorflow import TensorFlowModel
        
        # 추론 코드 생성
        inference_code = self.create_inference_script()
        
        # 추론 스크립트 저장
        with open('/tmp/inference.py', 'w') as f:
            f.write(inference_code)
        
        # TensorFlow 모델 생성
        tensorflow_model = TensorFlowModel(
            model_data=model_artifacts_s3_path,
            role=sagemaker.get_execution_role(),
            entry_point='inference.py',
            source_dir='/tmp/',
            framework_version='2.8',
            py_version='py39'
        )
        
        # 엔드포인트 배포
        predictor = tensorflow_model.deploy(
            initial_instance_count=1,
            instance_type='ml.m5.large',
            endpoint_name=self.endpoint_name
        )
        
        return predictor
    
    def predict_fire_risk(self, discrete_data):
        """실시간 화재 위험 예측"""
        try:
            # 데이터 형식 변환
            payload = {
                'voltage': discrete_data.get('volt', 0),
                'voltage_low': discrete_data.get('voltLow', 0),
                'current': discrete_data.get('ct', 0),
                'leakage_current': discrete_data.get('zct', 0),
                'resistive_leakage': discrete_data.get('rzct', 0),
                'power': discrete_data.get('pwr', 0),
                'pcb_temperature': discrete_data.get('pcbTemp', 0),
                'sensor_temperature': discrete_data.get('sensorTemp', 0),
                'co_gas': discrete_data.get('co', 0),
                'voc': discrete_data.get('voc', 0),
                'power_factor': discrete_data.get('pFct', 0),
                'arc_count': discrete_data.get('aArc', 0),
                'status_bits': discrete_data.get('status', 0)
            }
            
            # SageMaker 엔드포인트 호출
            response = self.sagemaker_client.invoke_endpoint(
                EndpointName=self.endpoint_name,
                ContentType='application/json',
                Body=json.dumps(payload)
            )
            
            # 결과 파싱
            result = json.loads(response['Body'].read().decode())
            
            return result
            
        except Exception as e:
            logger.error(f"SageMaker prediction error: {e}")
            return {
                'fire_probability': 0.5,
                'risk_level': 'UNKNOWN',
                'confidence': 0.0,
                'error': str(e)
            }

class BatchTransformJob:
    """배치 변환 작업"""
    
    def __init__(self):
        self.sagemaker_client = boto3.client('sagemaker')
        self.s3_client = boto3.client('s3')
        
    def create_batch_prediction_job(self, model_name, input_s3_path, output_s3_path):
        """배치 예측 작업 생성"""
        
        transform_job_name = f"fire-prediction-batch-{int(datetime.now().timestamp())}"
        
        try:
            response = self.sagemaker_client.create_transform_job(
                TransformJobName=transform_job_name,
                ModelName=model_name,
                BatchStrategy='MultiRecord',
                TransformInput={
                    'DataSource': {
                        'S3DataSource': {
                            'S3DataType': 'S3Prefix',
                            'S3Uri': input_s3_path
                        }
                    },
                    'ContentType': 'application/json',
                    'SplitType': 'Line'
                },
                TransformOutput={
                    'S3OutputPath': output_s3_path,
                    'Accept': 'application/json'
                },
                TransformResources={
                    'InstanceType': 'ml.m5.large',
                    'InstanceCount': 1
                }
            )
            
            return transform_job_name
            
        except Exception as e:
            logger.error(f"Batch transform job creation error: {e}")
            return None
    
    def monitor_batch_job(self, job_name):
        """배치 작업 모니터링"""
        while True:
            response = self.sagemaker_client.describe_transform_job(
                TransformJobName=job_name
            )
            
            status = response['TransformJobStatus']
            
            if status == 'Completed':
                print(f"Batch job {job_name} completed successfully")
                return True
            elif status == 'Failed':
                print(f"Batch job {job_name} failed: {response.get('FailureReason', 'Unknown')}")
                return False
            elif status == 'Stopping' or status == 'Stopped':
                print(f"Batch job {job_name} was stopped")
                return False
            
            print(f"Batch job {job_name} status: {status}")
            time.sleep(30)

class ModelMonitoring:
    """모델 모니터링 및 성능 추적"""
    
    def __init__(self):
        self.cloudwatch = boto3.client('cloudwatch')
        self.dynamodb = boto3.resource('dynamodb')
        self.model_metrics_table = self.dynamodb.Table('FirePrediction-ModelMetrics')
        
    def log_prediction_metrics(self, device_id, prediction_result, actual_outcome=None):
        """예측 메트릭 로깅"""
        try:
            # CloudWatch 메트릭
            metrics = [
                {
                    'MetricName': 'PredictionConfidence',
                    'Dimensions': [
                        {'Name': 'DeviceId', 'Value': str(device_id)},
                        {'Name': 'Model', 'Value': 'LSTM'}
                    ],
                    'Value': prediction_result['confidence'],
                    'Unit': 'None'
                },
                {
                    'MetricName': 'FireProbability',
                    'Dimensions': [
                        {'Name': 'DeviceId', 'Value': str(device_id)},
                        {'Name': 'Model', 'Value': 'LSTM'}
                    ],
                    'Value': prediction_result['fire_probability'],
                    'Unit': 'None'
                }
            ]
            
            self.cloudwatch.put_metric_data(
                Namespace='FirePrediction/ModelPerformance',
                MetricData=metrics
            )
            
            # DynamoDB에 상세 메트릭 저장
            item = {
                'device_id': str(device_id),
                'timestamp': datetime.now().isoformat(),
                'prediction_probability': Decimal(str(prediction_result['fire_probability'])),
                'predicted_risk_level': prediction_result['risk_level'],
                'confidence': Decimal(str(prediction_result['confidence'])),
                'model_version': 'LSTM_v1.0',
                'ttl': int((datetime.now().timestamp() + (90 * 24 * 60 * 60)))  # 90일
            }
            
            if actual_outcome is not None:
                item['actual_outcome'] = actual_outcome
                item['prediction_accuracy'] = 1 if (
                    (prediction_result['fire_probability'] > 0.5) == actual_outcome
                ) else 0
            
            self.model_metrics_table.put_item(Item=item)
            
        except Exception as e:
            logger.error(f"Model metrics logging error: {e}")
    
    def calculate_model_performance(self, days_back=7):
        """모델 성능 계산"""
        try:
            # 최근 N일간 예측 결과 조회
            end_time = datetime.now()
            start_time = end_time - timedelta(days=days_back)
            
            # 실제 결과가 있는 예측들만 조회
            response = self.model_metrics_table.scan(
                FilterExpression='attribute_exists(actual_outcome) AND #ts BETWEEN :start AND :end',
                ExpressionAttributeNames={'#ts': 'timestamp'},
                ExpressionAttributeValues={
                    ':start': start_time.isoformat(),
                    ':end': end_time.isoformat()
                }
            )
            
            predictions = response['Items']
            
            if len(predictions) < 10:  # 최소 10개 예측 필요
                return {'status': 'insufficient_data', 'count': len(predictions)}
            
            # 성능 메트릭 계산
            accuracies = [float(p['prediction_accuracy']) for p in predictions]
            confidences = [float(p['confidence']) for p in predictions]
            
            true_positives = sum(1 for p in predictions 
                               if p['actual_outcome'] == 1 and float(p['prediction_probability']) > 0.5)
            false_positives = sum(1 for p in predictions 
                                if p['actual_outcome'] == 0 and float(p['prediction_probability']) > 0.5)
            true_negatives = sum(1 for p in predictions 
                               if p['actual_outcome'] == 0 and float(p['prediction_probability']) <= 0.5)
            false_negatives = sum(1 for p in predictions 
                                if p['actual_outcome'] == 1 and float(p['prediction_probability']) <= 0.5)
            
            # 메트릭 계산
            accuracy = np.mean(accuracies)
            precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
            recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
            avg_confidence = np.mean(confidences)
            
            performance_metrics = {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1_score,
                'average_confidence': avg_confidence,
                'total_predictions': len(predictions),
                'true_positives': true_positives,
                'false_positives': false_positives,
                'true_negatives': true_negatives,
                'false_negatives': false_negatives,
                'evaluation_period_days': days_back
            }
            
            # CloudWatch에 성능 메트릭 전송
            self.send_performance_metrics_to_cloudwatch(performance_metrics)
            
            return performance_metrics
            
        except Exception as e:
            logger.error(f"Model performance calculation error: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def send_performance_metrics_to_cloudwatch(self, metrics):
        """성능 메트릭을 CloudWatch에 전송"""
        try:
            cloudwatch_metrics = [
                ('ModelAccuracy', metrics['accuracy']),
                ('ModelPrecision', metrics['precision']),
                ('ModelRecall', metrics['recall']),
                ('ModelF1Score', metrics['f1_score']),
                ('ModelAverageConfidence', metrics['average_confidence'])
            ]
            
            metric_data = []
            for metric_name, value in cloudwatch_metrics:
                metric_data.append({
                    'MetricName': metric_name,
                    'Dimensions': [
                        {'Name': 'Model', 'Value': 'LSTM'},
                        {'Name': 'Environment', 'Value': 'Production'}
                    ],
                    'Value': value,
                    'Unit': 'None'
                })
            
            self.cloudwatch.put_metric_data(
                Namespace='FirePrediction/ModelPerformance',
                MetricData=metric_data
            )
            
        except Exception as e:
            logger.error(f"CloudWatch performance metrics error: {e}")

# 통합 ML 서비스 클래스
class FirePredictionMLService:
    """화재 예측 ML 서비스 통합 클래스"""
    
    def __init__(self):
        self.pipeline = SageMakerMLPipeline()
        self.inference_endpoint = RealTimeInferenceEndpoint()
        self.batch_processor = BatchTransformJob()
        self.model_monitor = ModelMonitoring()
        
    def initialize_ml_pipeline(self):
        """ML 파이프라인 초기화"""
        # 파이프라인 생성 및 실행
        pipeline = self.pipeline.create_sagemaker_pipeline()
        execution = pipeline.start()
        
        return execution
    
    def deploy_production_model(self, model_artifacts_path):
        """프로덕션 모델 배포"""
        predictor = self.inference_endpoint.deploy_model(model_artifacts_path)
        return predictor
    
    def predict_with_monitoring(self, device_id, discrete_data):
        """모니터링과 함께 예측 수행"""
        # 예측 실행
        prediction = self.inference_endpoint.predict_fire_risk(discrete_data)
        
        # 메트릭 로깅
        self.model_monitor.log_prediction_metrics(device_id, prediction)
        
        return prediction

# AWS IoT Core 화재 예측 시스템 - Part 5: 대시보드, 모니터링 및 배포

# 5. 대시보드 및 모니터링 시스템
# 5.1 CloudWatch 대시보드

python

import boto3

import json
from datetime import datetime, timedelta

class CloudWatchDashboardManager:
    def __init__(self):
        self.cloudwatch = boto3.client('cloudwatch')
        
    def create_fire_prediction_dashboard(self):
        """화재 예측 시스템 대시보드 생성"""
        
        dashboard_body = {
            "widgets": [
                {
                    "type": "metric",
                    "x": 0, "y": 0, "width": 12, "height": 6,
                    "properties": {
                        "metrics": [
                            ["FirePrediction/Devices", "DeviceRiskScore", "DeviceId", "ALL"],
                            [".", "DeviceTemperature", ".", "."],
                            [".", "DeviceAlarmCount", ".", "."]
                        ],
                        "period": 300,
                        "stat": "Average",
                        "region": "us-east-1",
                        "title": "전체 디바이스 위험도 현황",
                        "yAxis": {
                            "left": {"min": 0, "max": 1}
                        }
                    }
                },
                {
                    "type": "metric",
                    "x": 12, "y": 0, "width": 12, "height": 6,
                    "properties": {
                        "metrics": [
                            ["FirePrediction/ModelPerformance", "ModelAccuracy", "Model", "LSTM"],
                            [".", "ModelPrecision", ".", "."],
                            [".", "ModelRecall", ".", "."],
                            [".", "ModelF1Score", ".", "."]
                        ],
                        "period": 3600,
                        "stat": "Average",
                        "region": "us-east-1",
                        "title": "모델 성능 메트릭",
                        "yAxis": {
                            "left": {"min": 0, "max": 1}
                        }
                    }
                },
                {
                    "type": "log",
                    "x": 0, "y": 6, "width": 24, "height": 6,
                    "properties": {
                        "query": "SOURCE '/aws/lambda/fire-prediction-processor'\n| fields @timestamp, device_id, risk_level, risk_score\n| filter risk_level in [\"HIGH\", \"CRITICAL\"]\n| sort @timestamp desc\n| limit 20",
                        "region": "us-east-1",
                        "title": "최근 고위험 알림",
                        "view": "table"
                    }
                },
                {
                    "type": "metric",
                    "x": 0, "y": 12, "width": 8, "height": 6,
                    "properties": {
                        "metrics": [
                            ["AWS/Lambda", "Duration", "FunctionName", "fire-prediction-processor"],
                            [".", "Errors", ".", "."],
                            [".", "Invocations", ".", "."]
                        ],
                        "period": 300,
                        "stat": "Sum",
                        "region": "us-east-1",
                        "title": "Lambda 성능"
                    }
                },
                {
                    "type": "metric",
                    "x": 8, "y": 12, "width": 8, "height": 6,
                    "properties": {
                        "metrics": [
                            ["AWS/Kinesis", "IncomingRecords", "StreamName", "fire-prediction-stream"],
                            [".", "OutgoingRecords", ".", "."],
                            [".", "WriteProvisionedThroughputExceeded", ".", "."]
                        ],
                        "period": 300,
                        "stat": "Sum",
                        "region": "us-east-1",
                        "title": "Kinesis 스트림 상태"
                    }
                },
                {
                    "type": "metric",
                    "x": 16, "y": 12, "width": 8, "height": 6,
                    "properties": {
                        "metrics": [
                            ["AWS/DynamoDB", "ConsumedReadCapacityUnits", "TableName", "FirePrediction-RawData"],
                            [".", "ConsumedWriteCapacityUnits", ".", "."],
                            [".", "ThrottledRequests", ".", "."]
                        ],
                        "period": 300,
                        "stat": "Sum",
                        "region": "us-east-1",
                        "title": "DynamoDB 사용량"
                    }
                }
            ]
        }
        
        try:
            response = self.cloudwatch.put_dashboard(
                DashboardName='FirePredictionSystem',
                DashboardBody=json.dumps(dashboard_body)
            )
            print("Dashboard created successfully")
            return response
        except Exception as e:
            print(f"Dashboard creation error: {e}")
            return None

class AlarmManager:
    """CloudWatch 알람 관리"""
    
    def __init__(self):
        self.cloudwatch = boto3.client('cloudwatch')
        self.sns = boto3.client('sns')
        
    def create_system_alarms(self):
        """시스템 알람 생성"""
        
        alarms = [
            {
                'AlarmName': 'HighRiskDeviceCount',
                'ComparisonOperator': 'GreaterThanThreshold',
                'EvaluationPeriods': 2,
                'MetricName': 'DeviceRiskScore',
                'Namespace': 'FirePrediction/Devices',
                'Period': 300,
                'Statistic': 'Average',
                'Threshold': 0.7,
                'ActionsEnabled': True,
                'AlarmActions': [
                    os.environ.get('HIGH_RISK_SNS_TOPIC_ARN')
                ],
                'AlarmDescription': '고위험 디바이스 감지',
                'Unit': 'None'
            },
            {
                'AlarmName': 'ModelAccuracyDrop',
                'ComparisonOperator': 'LessThanThreshold',
                'EvaluationPeriods': 3,
                'MetricName': 'ModelAccuracy',
                'Namespace': 'FirePrediction/ModelPerformance',
                'Period': 3600,
                'Statistic': 'Average',
                'Threshold': 0.85,
                'ActionsEnabled': True,
                'AlarmActions': [
                    os.environ.get('MODEL_ALERT_SNS_TOPIC_ARN')
                ],
                'AlarmDescription': '모델 정확도 하락',
                'Unit': 'None'
            },
            {
                'AlarmName': 'LambdaErrorRate',
                'ComparisonOperator': 'GreaterThanThreshold',
                'EvaluationPeriods': 2,
                'MetricName': 'Errors',
                'Namespace': 'AWS/Lambda',
                'Period': 300,
                'Statistic': 'Sum',
                'Threshold': 5,
                'ActionsEnabled': True,
                'AlarmActions': [
                    os.environ.get('SYSTEM_ALERT_SNS_TOPIC_ARN')
                ],
                'AlarmDescription': 'Lambda 함수 오류율 증가',
                'Dimensions': [
                    {'Name': 'FunctionName', 'Value': 'fire-prediction-processor'}
                ]
            },
            {
                'AlarmName': 'KinesisThrottling',
                'ComparisonOperator': 'GreaterThanThreshold',
                'EvaluationPeriods': 1,
                'MetricName': 'WriteProvisionedThroughputExceeded',
                'Namespace': 'AWS/Kinesis',
                'Period': 300,
                'Statistic': 'Sum',
                'Threshold': 0,
                'ActionsEnabled': True,
                'AlarmActions': [
                    os.environ.get('SYSTEM_ALERT_SNS_TOPIC_ARN')
                ],
                'AlarmDescription': 'Kinesis 스트림 스로틀링 발생',
                'Dimensions': [
                    {'Name': 'StreamName', 'Value': 'fire-prediction-stream'}
                ]
            },
            {
                'AlarmName': 'DynamoDBThrottling',
                'ComparisonOperator': 'GreaterThanThreshold',
                'EvaluationPeriods': 1,
                'MetricName': 'ThrottledRequests',
                'Namespace': 'AWS/DynamoDB',
                'Period': 300,
                'Statistic': 'Sum',
                'Threshold': 0,
                'ActionsEnabled': True,
                'AlarmActions': [
                    os.environ.get('SYSTEM_ALERT_SNS_TOPIC_ARN')
                ],
                'AlarmDescription': 'DynamoDB 스로틀링 발생',
                'Dimensions': [
                    {'Name': 'TableName', 'Value': 'FirePrediction-RawData'}
                ]
            },
            {
                'AlarmName': 'HighTemperatureDevices',
                'ComparisonOperator': 'GreaterThanThreshold',
                'EvaluationPeriods': 1,
                'MetricName': 'DeviceTemperature',
                'Namespace': 'FirePrediction/Devices',
                'Period': 300,
                'Statistic': 'Maximum',
                'Threshold': 65,
                'ActionsEnabled': True,
                'AlarmActions': [
                    os.environ.get('CRITICAL_ALERT_TOPIC_ARN')
                ],
                'AlarmDescription': '65도 이상 고온 디바이스 감지',
                'Unit': 'None'
            }
        ]
        
        for alarm in alarms:
            try:
                self.cloudwatch.put_metric_alarm(**alarm)
                print(f"Alarm created: {alarm['AlarmName']}")
            except Exception as e:
                print(f"Error creating alarm {alarm['AlarmName']}: {e}")
    
    def create_composite_alarm(self):
        """복합 알람 생성 - 여러 조건 조합"""
        try:
            composite_alarm = {
                'AlarmName': 'FirePredictionSystemHealth',
                'AlarmDescription': '화재 예측 시스템 전체 건강도',
                'ActionsEnabled': True,
                'AlarmActions': [
                    os.environ.get('SYSTEM_ALERT_SNS_TOPIC_ARN')
                ],
                'AlarmRule': (
                    "ALARM('HighRiskDeviceCount') OR "
                    "ALARM('LambdaErrorRate') OR "
                    "ALARM('KinesisThrottling') OR "
                    "ALARM('DynamoDBThrottling')"
                )
            }
            
            self.cloudwatch.put_composite_alarm(**composite_alarm)
            print("Composite alarm created successfully")
            
        except Exception as e:
            print(f"Error creating composite alarm: {e}")

# 5.2 웹 대시보드 구현

# python

from flask import Flask, render_template, jsonify, request
import boto3
from datetime import datetime, timedelta
import json

app = Flask(__name__)

class WebDashboard:
    def __init__(self):
        self.dynamodb = boto3.resource('dynamodb')
        self.cloudwatch = boto3.client('cloudwatch')
        self.raw_data_table = self.dynamodb.Table('FirePrediction-RawData')
        self.device_state_table = self.dynamodb.Table('FirePrediction-DeviceState')
        self.alerts_table = self.dynamodb.Table('FirePrediction-Alerts')

@app.route('/')
def dashboard():
    """메인 대시보드"""
    return render_template('dashboard.html')

@app.route('/api/overview')
def get_overview():
    """시스템 개요 API"""
    dashboard = WebDashboard()
    
    try:
        # 활성 디바이스 수
        response = dashboard.device_state_table.scan()
        all_devices = response['Items']
        
        # 최근 5분 내 활성 디바이스
        cutoff_time = (datetime.now() - timedelta(minutes=5)).isoformat()
        active_devices = [d for d in all_devices 
                         if d.get('last_seen', '') > cutoff_time]
        
        # 위험도별 분포
        risk_distribution = {'NORMAL': 0, 'LOW': 0, 'MEDIUM': 0, 'HIGH': 0, 'CRITICAL': 0}
        for device in active_devices:
            risk_level = device.get('current_risk_level', 'NORMAL')
            risk_distribution[risk_level] += 1
        
        # 최근 알림
        recent_alerts_response = dashboard.alerts_table.scan(
            FilterExpression='alert_timestamp > :cutoff',
            ExpressionAttributeValues={':cutoff': cutoff_time},
            Limit=10
        )
        
        return jsonify({
            'total_devices': len(all_devices),
            'active_devices': len(active_devices),
            'risk_distribution': risk_distribution,
            'recent_alerts': recent_alerts_response['Items'][:5],
            'system_status': 'HEALTHY' if len(active_devices) > len(all_devices) * 0.8 else 'DEGRADED'
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/device/<device_id>')
def get_device_details(device_id):
    """특정 디바이스 상세 정보"""
    dashboard = WebDashboard()
    
    try:
        # 디바이스 상태
        device_response = dashboard.device_state_table.get_item(
            Key={'device_id': device_id}
        )
        
        if 'Item' not in device_response:
            return jsonify({'error': 'Device not found'}), 404
        
        device_info = device_response['Item']
        
        # 최근 24시간 데이터
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=24)
        
        history_response = dashboard.raw_data_table.query(
            KeyConditionExpression=Key('device_id').eq(device_id) & 
                                 Key('timestamp').between(
                                     start_time.isoformat(),
                                     end_time.isoformat()
                                 ),
            ScanIndexForward=False,
            Limit=100
        )
        
        history_data = history_response['Items']
        
        # 시계열 데이터 준비
        timeseries = []
        for item in reversed(history_data):
            timeseries.append({
                'timestamp': item['timestamp'],
                'temperature': max(float(item.get('pcb_temperature', 0)), 
                                 float(item.get('sensor_temperature', 0))),
                'risk_score': float(item.get('risk_indicators', {}).get('total_risk_score', 0)),
                'arc_count': int(item.get('arc_count', 0)),
                'voltage': float(item.get('voltage', 0)),
                'current': float(item.get('current', 0))
            })
        
        # 디바이스별 알림
        alerts_response = dashboard.alerts_table.query(
            KeyConditionExpression=Key('device_id').eq(device_id),
            ScanIndexForward=False,
            Limit=20
        )
        
        return jsonify({
            'device_info': device_info,
            'timeseries_data': timeseries,
            'recent_alerts': alerts_response['Items'],
            'recommendations': generate_device_recommendations(device_info, history_data)
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/realtime/<device_id>')
def get_realtime_data(device_id):
    """실시간 데이터 스트림"""
    dashboard = WebDashboard()
    
    try:
        # 최근 1분 데이터
        end_time = datetime.now()
        start_time = end_time - timedelta(minutes=1)
        
        response = dashboard.raw_data_table.query(
            KeyConditionExpression=Key('device_id').eq(device_id) & 
                                 Key('timestamp').gte(start_time.isoformat()),
            ScanIndexForward=False,
            Limit=5
        )
        
        latest_data = response['Items'][0] if response['Items'] else None
        
        if latest_data:
            return jsonify({
                'timestamp': latest_data['timestamp'],
                'temperature': max(float(latest_data.get('pcb_temperature', 0)),
                                 float(latest_data.get('sensor_temperature', 0))),
                'risk_score': float(latest_data.get('risk_indicators', {}).get('total_risk_score', 0)),
                'voltage': float(latest_data.get('voltage', 0)),
                'current': float(latest_data.get('current', 0)),
                'arc_count': int(latest_data.get('arc_count', 0)),
                'alarm_status': latest_data.get('alarm_status', {}),
                'status_bits': int(latest_data.get('status_bits', 0))
            })
        else:
            return jsonify({'error': 'No recent data'}), 404
            
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/metrics')
def get_system_metrics():
    """시스템 메트릭 API"""
    dashboard = WebDashboard()
    
    try:
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=1)
        
        # CloudWatch 메트릭 조회
        metrics = {}
        
        # Lambda 메트릭
        lambda_response = dashboard.cloudwatch.get_metric_statistics(
            Namespace='AWS/Lambda',
            MetricName='Invocations',
            Dimensions=[{'Name': 'FunctionName', 'Value': 'fire-prediction-processor'}],
            StartTime=start_time,
            EndTime=end_time,
            Period=300,
            Statistics=['Sum']
        )
        
        metrics['lambda_invocations'] = lambda_response['Datapoints']
        
        # Kinesis 메트릭
        kinesis_response = dashboard.cloudwatch.get_metric_statistics(
            Namespace='AWS/Kinesis',
            MetricName='IncomingRecords',
            Dimensions=[{'Name': 'StreamName', 'Value': 'fire-prediction-stream'}],
            StartTime=start_time,
            EndTime=end_time,
            Period=300,
            Statistics=['Sum']
        )
        
        metrics['kinesis_records'] = kinesis_response['Datapoints']
        
        return jsonify(metrics)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def generate_device_recommendations(device_info, history_data):
    """디바이스별 권장사항 생성"""
    recommendations = []
    
    current_risk = float(device_info.get('current_risk_score', 0))
    last_temp = float(device_info.get('last_temperature', 0))
    total_alarms = int(device_info.get('total_alarms', 0))
    
    if current_risk > 0.7:
        recommendations.append({
            'priority': 'HIGH',
            'type': 'IMMEDIATE_INSPECTION',
            'message': '즉시 현장 점검이 필요합니다.',
            'action': 'INSPECT'
        })
    
    if last_temp > 60:
        recommendations.append({
            'priority': 'HIGH',
            'type': 'COOLING_CHECK',
            'message': '냉각 시스템 점검 및 환기 확인이 필요합니다.',
            'action': 'MAINTENANCE'
        })
    
    if total_alarms > 10:
        recommendations.append({
            'priority': 'MEDIUM',
            'type': 'ALARM_ANALYSIS',
            'message': '반복적인 알람 발생 원인 분석이 필요합니다.',
            'action': 'ANALYZE'
        })
    
    # 히스토리 기반 권장사항
    if len(history_data) > 10:
        arc_counts = [int(item.get('arc_count', 0)) for item in history_data[-10:]]
        if sum(arc_counts) > 5:
            recommendations.append({
                'priority': 'MEDIUM',
                'type': 'ELECTRICAL_CHECK',
                'message': '전기 연결부 및 절연 상태 점검을 권장합니다.',
                'action': 'MAINTENANCE'
            })
    
    return recommendations

### 5.3 HTML 템플릿들

#### dashboard.html (메인 대시보드)

```html
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>화재 예측 시스템 대시보드</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <style>
        body { font-family: Arial, sans-serif; margin: 0; padding: 20px; background: #f5f5f5; }
        .header { background: #2c3e50; color: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; }
        .dashboard-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }
        .card { background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        .metric { text-align: center; margin: 10px 0; }
        .metric-value { font-size: 2em; font-weight: bold; }
        .metric-label { color: #666; }
        .risk-high { color: #e74c3c; }
        .risk-medium { color: #f39c12; }
        .risk-low { color: #27ae60; }
        .alert-item { padding: 10px; margin: 5px 0; border-left: 4px solid #e74c3c; background: #f8f9fa; }
        .device-list { max-height: 400px; overflow-y: auto; }
        .device-item { padding: 10px; border-bottom: 1px solid #eee; cursor: pointer; }
        .device-item:hover { background: #f8f9fa; }
        .status-indicator { width: 10px; height: 10px; border-radius: 50%; display: inline-block; margin-right: 10px; }
        .status-normal { background: #27ae60; }
        .status-warning { background: #f39c12; }
        .status-critical { background: #e74c3c; }
    </style>
</head>
<body>
    <div class="header">
        <h1>🔥 화재 예측 시스템 대시보드</h1>
        <p>실시간 IoT 디바이스 모니터링 및 화재 위험 예측</p>
    </div>

    <div class="dashboard-grid">
        <!-- 시스템 개요 -->
        <div class="card">
            <h3>시스템 개요</h3>
            <div class="metric">
                <div class="metric-value" id="total-devices">-</div>
                <div class="metric-label">총 디바이스</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="active-devices">-</div>
                <div class="metric-label">활성 디바이스</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="system-status">-</div>
                <div class="metric-label">시스템 상태</div>
            </div>
        </div>

        <!-- 위험도 분포 -->
        <div class="card">
            <h3>위험도 분포</h3>
            <canvas id="risk-distribution-chart" width="400" height="200"></canvas>
        </div>

        <!-- 최근 알림 -->
        <div class="card">
            <h3>최근 알림</h3>
            <div id="recent-alerts" class="alert-list">
                <!-- 알림 목록이 여기에 표시됩니다 -->
            </div>
        </div>

        <!-- 디바이스 목록 -->
        <div class="card">
            <h3>디바이스 목록</h3>
            <div id="device-list" class="device-list">
                <!-- 디바이스 목록이 여기에 표시됩니다 -->
            </div>
        </div>

        <!-- 실시간 메트릭 -->
        <div class="card">
            <h3>실시간 메트릭</h3>
            <canvas id="realtime-metrics-chart" width="400" height="200"></canvas>
        </div>

        <!-- 시스템 성능 -->
        <div class="card">
            <h3>시스템 성능</h3>
            <div class="metric">
                <div class="metric-value" id="lambda-invocations">-</div>
                <div class="metric-label">Lambda 호출/시간</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="kinesis-records">-</div>
                <div class="metric-label">Kinesis 레코드/시간</div>
            </div>
        </div>
    </div>

    <script>
        // 차트 초기화
        let riskChart, metricsChart;
        
        function initCharts() {
            // 위험도 분포 차트
            const riskCtx = document.getElementById('risk-distribution-chart').getContext('2d');
            riskChart = new Chart(riskCtx, {
                type: 'doughnut',
                data: {
                    labels: ['정상', '낮음', '보통', '높음', '위험'],
                    datasets: [{
                        data: [0, 0, 0, 0, 0],
                        backgroundColor: ['#27ae60', '#2ecc71', '#f39c12', '#e67e22', '#e74c3c']
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false
                }
            });

            // 실시간 메트릭 차트
            const metricsCtx = document.getElementById('realtime-metrics-chart').getContext('2d');
            metricsChart = new Chart(metricsCtx, {
                type: 'line',
                data: {
                    labels: [],
                    datasets: [{
                        label: '평균 위험도',
                        data: [],
                        borderColor: '#e74c3c',
                        tension: 0.1
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        y: {
                            beginAtZero: true,
                            max: 1
                        }
                    }
                }
            });
        }

        function updateOverview() {
            $.get('/api/overview', function(data) {
                $('#total-devices').text(data.total_devices);
                $('#active-devices').text(data.active_devices);
                $('#system-status').text(data.system_status);
                
                // 위험도 분포 업데이트
                const distribution = data.risk_distribution;
                riskChart.data.datasets[0].data = [
                    distribution.NORMAL,
                    distribution.LOW,
                    distribution.MEDIUM,
                    distribution.HIGH,
                    distribution.CRITICAL
                ];
                riskChart.update();
                
                // 최근 알림 업데이트
                const alertsHtml = data.recent_alerts.map(alert => `
                    <div class="alert-item">
                        <strong>디바이스 ${alert.device_id}</strong> - ${alert.alert_level}<br>
                        <small>${new Date(alert.alert_timestamp).toLocaleString()}</small>
                    </div>
                `).join('');
                $('#recent-alerts').html(alertsHtml);
            });
        }

        function updateMetrics() {
            $.get('/api/metrics', function(data) {
                if (data.lambda_invocations && data.lambda_invocations.length > 0) {
                    const latest = data.lambda_invocations[data.lambda_invocations.length - 1];
                    $('#lambda-invocations').text(latest.Sum || 0);
                }
                
                if (data.kinesis_records && data.kinesis_records.length > 0) {
                    const latest = data.kinesis_records[data.kinesis_records.length - 1];
                    $('#kinesis-records').text(latest.Sum || 0);
                }
            });
        }

        // 초기화 및 주기적 업데이트
        $(document).ready(function() {
            initCharts();
            updateOverview();
            updateMetrics();
            
            // 5초마다 업데이트
            setInterval(updateOverview, 5000);
            setInterval(updateMetrics, 10000);
        });
    </script>
</body>
</html>

# 6. 시스템 배포 및 Infrastructure as Code

# 6.1 CloudFormation 템플릿
# yaml

AWSTemplateFormatVersion: '2010-09-09'
Description: 'AWS IoT Core 기반 화재 예측 시스템'

Parameters:
  Environment:
    Type: String
    Default: 'dev'
    AllowedValues: ['dev', 'staging', 'prod']
  
  NotificationEmail:
    Type: String
    Description: '알림을 받을 이메일 주소'

Resources:
  # IAM 역할
  IoTFirePredictionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: [lambda.amazonaws.com, iot.amazonaws.com, sagemaker.amazonaws.com]
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
        - arn:aws:iam::aws:policy/AmazonDynamoDBFullAccess
        - arn:aws:iam::aws:policy/AmazonKinesisFullAccess
        - arn:aws:iam::aws:policy/AmazonSNSFullAccess
        - arn:aws:iam::aws:policy/CloudWatchFullAccess
        - arn:aws:iam::aws:policy/AmazonSageMakerFullAccess

  # DynamoDB 테이블들
  RawDataTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: !Sub 'FirePrediction-RawData-${Environment}'
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: device_id
          AttributeType: S
        - AttributeName: timestamp
          AttributeType: S
      KeySchema:
        - AttributeName: device_id
          KeyType: HASH
        - AttributeName: timestamp
          KeyType: RANGE
      TimeToLiveSpecification:
        AttributeName: ttl
        Enabled: true
      StreamSpecification:
        StreamViewType: NEW_AND_OLD_IMAGES

  DeviceStateTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: !Sub 'FirePrediction-DeviceState-${Environment}'
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: device_id
          AttributeType: S
      KeySchema:
        - AttributeName: device_id
          KeyType: HASH

  AlertsTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: !Sub 'FirePrediction-Alerts-${Environment}'
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: device_id
          AttributeType: S
        - AttributeName: alert_timestamp
          AttributeType: S
      KeySchema:
        - AttributeName: device_id
          KeyType: HASH
        - AttributeName: alert_timestamp
          KeyType: RANGE
      TimeToLiveSpecification:
        AttributeName: ttl
        Enabled: true

  # Kinesis Stream
  FirePredictionStream:
    Type: AWS::Kinesis::Stream
    Properties:
      Name: !Sub 'fire-prediction-stream-${Environment}'
      ShardCount: 2
      RetentionPeriodHours: 24

  # SNS 토픽들
  CriticalAlertTopic:
    Type: AWS::SNS::Topic
    Properties:
      TopicName: !Sub 'fire-prediction-critical-alerts-${Environment}'
      Subscription:
        - Endpoint: !Ref NotificationEmail
          Protocol: email

  HighRiskAlertTopic:
    Type: AWS::SNS::Topic
    Properties:
      TopicName: !Sub 'fire-prediction-high-risk-alerts-${Environment}'
      Subscription:
        - Endpoint: !Ref NotificationEmail
          Protocol: email

  # Lambda 함수
  FirePredictionProcessor:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub 'fire-prediction-processor-${Environment}'
      Runtime: python3.9
      Handler: lambda_function.lambda_handler
      Role: !GetAtt IoTFirePredictionRole.Arn
      Timeout: 300
      MemorySize: 512
      Environment:
        Variables:
          KINESIS_STREAM_NAME: !Ref FirePredictionStream
          CRITICAL_ALERT_TOPIC_ARN: !Ref CriticalAlertTopic
          HIGH_RISK_ALERT_TOPIC_ARN: !Ref HighRiskAlertTopic
          ENVIRONMENT: !Ref Environment
      Code:
        ZipFile: |
          # Lambda 코드가 여기에 포함됩니다
          def lambda_handler(event, context):
              return {'statusCode': 200}

  # IoT Rule
  FirePredictionIoTRule:
    Type: AWS::IoT::TopicRule
    Properties:
      RuleName: !Sub 'FirePredictionRule${Environment}'
      TopicRulePayload:
        Sql: !Sub |
          SELECT deviceId, idx, status, volt, voltLow, ct as current, 
                 zct as leakage_current, rzct as resistive_leakage, 
                 pwr as power, pcbTemp, sensorTemp, co, voc, 
                 pFct as power_factor, aArc as arc_count, 
                 timestamp() as timestamp
          FROM 'fire-prediction/device/+/data'
          WHERE status < 4096
        Actions:
          - Lambda:
              FunctionArn: !GetAtt FirePredictionProcessor.Arn

  # Lambda 권한 (IoT Rule에서 호출)
  LambdaInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref FirePredictionProcessor
      Action: lambda:InvokeFunction
      Principal: iot.amazonaws.com
      SourceArn: !GetAtt FirePredictionIoTRule.Arn

Outputs:
  StreamName:
    Description: 'Kinesis Stream Name'
    Value: !Ref FirePredictionStream
    Export:
      Name: !Sub '${AWS::StackName}-StreamName'
  
  ProcessorFunctionArn:
    Description: 'Lambda Function ARN'
    Value: !GetAtt FirePredictionProcessor.Arn
    Export:
      Name: !Sub '${AWS::StackName}-ProcessorFunctionArn'

# 6.2 배포 스크립트

# bash

#!/bin/bash
# deploy.sh - 화재 예측 시스템 배포 스크립트

set -e

ENVIRONMENT=${1:-dev}
REGION=${2:-us-east-1}
EMAIL=${3:-admin@example.com}
STACK_NAME="fire-prediction-system-${ENVIRONMENT}"

echo "🚀 화재 예측 시스템 배포 시작 - 환경: ${ENVIRONMENT}"

# 1. CloudFormation 스택 배포
echo "📦 CloudFormation 스택 배포 중..."
aws cloudformation deploy \
  --template-file cloudformation.yaml \
  --stack-name ${STACK_NAME} \
  --parameter-overrides \
    Environment=${ENVIRONMENT} \
    NotificationEmail=${EMAIL} \
  --capabilities CAPABILITY_IAM \
  --region ${REGION}

# 2. Lambda 함수 코드 패키징 및 업데이트
echo "📝 Lambda 함수 코드 업데이트 중..."
cd lambda
pip install -r requirements.txt -t .
zip -r ../lambda-deployment.zip .
cd ..

aws lambda update-function-code \
  --function-name fire-prediction-processor-${ENVIRONMENT} \
  --zip-file fileb://lambda-deployment.zip \
  --region ${REGION}

# 3. SageMaker 모델 배포 (선택적)
if [ "${ENVIRONMENT}" = "prod" ]; then
    echo "🤖 SageMaker 모델 배포 중..."
    python3 deploy_sagemaker.py --environment ${ENVIRONMENT}
fi

# 4. 모니터링 대시보드 설정
echo "📊 CloudWatch 대시보드 설정 중..."
python3 setup_dashboard.py --environment ${ENVIRONMENT}

# 5. 초기 테스트 데이터 전송
echo "🧪 시스템 테스트 중..."
python3 test_system.py --environment ${ENVIRONMENT}

echo "✅ 배포 완료!"
echo "📈 대시보드: https://console.aws.amazon.com/cloudwatch/home?region=${REGION}#dashboards:name=FirePredictionSystem"
echo "📋 로그: https://console.aws.amazon.com/cloudwatch/home?region=${REGION}#logsV2:log-groups/log-group/%2Faws%2Flambda%2Ffire-prediction-processor-${ENVIRONMENT}"

# 6.3 운영 가이드

# markdown

# 화재 예측 시스템 운영 가이드

## 일일 체크리스트

### 시스템 상태 확인
- [ ] CloudWatch 대시보드에서 전체 시스템 상태 확인
- [ ] 활성 디바이스 수가 예상 범위 내인지 확인
- [ ] Lambda 함수 오류율이 5% 미만인지 확인
- [ ] Kinesis 스트림에 데이터가 정상 유입되는지 확인

### 알림 및 경고 검토
- [ ] 지난 24시간 내 발생한 CRITICAL/HIGH 알림 검토
- [ ] 알림의 적정성 평가 (False Positive 여부)
- [ ] 조치가 필요한 디바이스 식별 및 현장팀 전달
- [ ] 알림 패턴 분석 (특정 시간대/위치 집중 여부)

### 성능 메트릭 모니터링
- [ ] 모델 정확도가 85% 이상 유지되는지 확인
- [ ] 평균 응답 시간이 2초 이하인지 확인
- [ ] DynamoDB 읽기/쓰기 용량 사용률 확인
- [ ] 비용 사용량 모니터링

## 주간 체크리스트

### 모델 성능 분석
- [ ] 주간 모델 성능 리포트 생성
- [ ] Precision, Recall, F1-Score 트렌드 분석
- [ ] 오탐(False Positive) 및 미탐(False Negative) 사례 분석
- [ ] 필요시 모델 재학습 계획 수립

### 시스템 최적화
- [ ] 리소스 사용량 분석 및 최적화 기회 식별
- [ ] 로그 분석을 통한 성능 병목 지점 파악
- [ ] 디바이스별 데이터 품질 평가
- [ ] 알림 임계값 조정 필요성 검토

### 데이터 품질 관리
- [ ] 센서 데이터 이상치 패턴 분석
- [ ] 통신 오류 빈도 분석
- [ ] 디바이스별 데이터 완결성 검사
- [ ] 새로운 센서 유형 또는 패턴 식별

## 월간 체크리스트

### 시스템 유지보수
- [ ] 전체 시스템 아키텍처 검토
- [ ] 보안 취약점 점검 및 패치 적용
- [ ] 백업 및 복구 절차 테스트
- [ ] 용량 계획 및 확장성 검토

### 비즈니스 가치 평가
- [ ] 화재 예방 효과 측정
- [ ] ROI(투자 수익률) 계산
- [ ] 사용자 피드백 수집 및 분석
- [ ] 시스템 개선 우선순위 설정

## 장애 대응 절차

### Level 1: 경미한 문제
**증상**: 일부 디바이스 오프라인, 가끔 발생하는 Lambda 오류
**대응**:
1. CloudWatch 로그에서 오류 패턴 확인
2. 영향받는 디바이스 재시작 시도
3. 24시간 모니터링 후 자동 복구되지 않으면 Level 2로 escalate

### Level 2: 중간 수준 문제
**증상**: 다수 디바이스 오프라인, Lambda 오류율 > 10%, 모델 정확도 급격한 하락
**대응**:
1. 즉시 운영팀에 알림
2. 시스템 상태 상세 진단
3. 필요시 백업 시스템으로 전환
4. 근본 원인 분석 및 임시 해결책 적용

### Level 3: 심각한 장애
**증상**: 시스템 전체 다운, 데이터 유실, 보안 침해
**대응**:
1. 즉시 모든 이해관계자에게 긴급 알림
2. 장애 복구팀 소집
3. 비상 절차 활성화
4. 외부 지원 요청 검토

## 모니터링 메트릭 기준값

### 시스템 성능
- Lambda 함수 응답 시간: < 2초 (목표), < 5초 (경고)
- Kinesis 처리 지연: < 1분 (목표), < 5분 (경고)
- DynamoDB 응답 시간: < 100ms (목표), < 500ms (경고)

### 모델 성능
- 정확도(Accuracy): > 90% (목표), > 85% (최소)
- 정밀도(Precision): > 85% (목표), > 80% (최소)
- 재현율(Recall): > 90% (목표), > 85% (최소)

### 비즈니스 메트릭
- 허위 경보율: < 5% (목표), < 10% (허용)
- 시스템 가용성: > 99.9% (목표), > 99.5% (최소)
- 평균 감지 시간: < 5분 (목표), < 15분 (최대)

## 백업 및 복구

### 데이터 백업
- DynamoDB: Point-in-time recovery 활성화
- S3: Cross-region replication 설정
- 모델 아티팩트: 다중 리전 백업

### 복구 절차
1. **RTO (Recovery Time Objective)**: 30분
2. **RPO (Recovery Point Objective)**: 5분
3. **복구 우선순위**: 실시간 모니터링 > 알림 시스템 > 분석 기능

## 보안 가이드라인

### 접근 제어
- IAM 역할 기반 최소 권한 원칙 적용
- 정기적인 권한 검토 및 감사
- Multi-factor authentication 필수

### 데이터 보호
- 전송 중 암호화 (TLS 1.2+)
- 저장 중 암호화 (AES-256)
- 개인정보 최소 수집 원칙

### 규정 준수
- 관련 산업 표준 및 규정 준수
- 정기적인 보안 감사 실시
- 사고 대응 절차 문서화

## 성능 최적화 가이드

### 비용 최적화

```python
# 비용 모니터링 스크립트
import boto3
from datetime import datetime, timedelta

def monitor_costs():
    ce_client = boto3.client('ce')
    
    end_date = datetime.now()
    start_date = end_date - timedelta(days=30)
    
    response = ce_client.get_cost_and_usage(
        TimePeriod={
            'Start': start_date.strftime('%Y-%m-%d'),
            'End': end_date.strftime('%Y-%m-%d')
        },
        Granularity='DAILY',
        Metrics=['BlendedCost'],
        GroupBy=[
            {'Type': 'DIMENSION', 'Key': 'SERVICE'}
        ]
    )
    
    # 서비스별 비용 분석
    for result in response['ResultsByTime']:
        print(f"Date: {result['TimePeriod']['Start']}")
        for group in result['Groups']:
            service = group['Keys'][0]
            cost = group['Metrics']['BlendedCost']['Amount']
            print(f"  {service}: ${cost}")

if __name__ == "__main__":
    monitor_costs()

# 자동 스케일링 설정

# yaml

# CloudWatch 기반 자동 스케일링
AutoScalingPolicy:
  Type: AWS::ApplicationAutoScaling::ScalingPolicy
  Properties:
    PolicyName: FirePredictionAutoScaling
    PolicyType: TargetTrackingScaling
    TargetTrackingScalingPolicyConfiguration:
      TargetValue: 70.0
      PredefinedMetricSpecification:
        PredefinedMetricType: DynamoDBReadCapacityUtilization

# 문제 해결 가이드

# 자주 발생하는 문제들

# 1. Lambda 함수 타임아웃
- 원인: 대량 데이터 처리, DynamoDB 응답 지연
- 해결책:

- 타임아웃 시간 증가 (최대 15분)
- 배치 크기 조정
- DynamoDB 읽기/쓰기 용량 증가

# 2. Kinesis 스트림 지연
원인: 샤드 수 부족, 처리 지연
해결책:

샤드 수 증가
병렬 처리 로직 최적화
배치 크기 조정

# 3. 모델 성능 저하
원인: 데이터 드리프트, 개념 드리프트
해결책:

새로운 데이터로 모델 재학습
특징 엔지니어링 개선
앙상블 모델 적용

# 4. 높은 오탐률
원인: 임계값 설정 부적절, 환경 변화
해결책:

임계값 동적 조정
컨텍스트 정보 추가 고려
다단계 검증 로직 적용

# 연락처 및 지원
# 긴급 상황

24/7 지원 핫라인: 1588-0000
이메일: emergency@company.com
Slack: #fire-prediction-emergency

일반 지원

기술 지원: tech-support@company.com
문서 및 교육: docs@company.com
피드백: feedback@company.com

개발팀

시스템 아키텍트: architect@company.com
ML 엔지니어: ml-team@company.com
DevOps: devops@company.com


## 시스템 테스트 및 검증

### 단위 테스트

```python
import unittest
import json
from unittest.mock import patch, MagicMock
from lambda_function import lambda_handler, DiscreteDataProcessor

class TestFirePredictionSystem(unittest.TestCase):
    
    def setUp(self):
        self.test_discrete_data = {
            'deviceId': 'TEST001',
            'idx': 1,
            'status': 0,  # 정상 상태
            'volt': 220.0,
            'voltLow': 220.0,
            'ct': 5.0,
            'zct': 0.5,
            'rzct': 0.3,
            'pwr': 1.1,
            'pcbTemp': 35.0,
            'sensorTemp': 37.0,
            'co': 5.0,
            'voc': 50.0,
            'pFct': 0.95,
            'aArc': 0,
            'timestamp': '2024-01-01T12:00:00Z'
        }
    
    def test_discrete_data_parsing(self):
        """Discrete 데이터 파싱 테스트"""
        processor = DiscreteDataProcessor()
        result = processor.parse_discrete_data(self.test_discrete_data)
        
        self.assertIsNotNone(result)
        self.assertEqual(result['device_id'], 'TEST001')
        self.assertEqual(result['voltage'], 220.0)
        self.assertEqual(result['current'], 5.0)
    
    def test_status_bit_parsing(self):
        """상태 비트 파싱 테스트"""
        processor = DiscreteDataProcessor()
        
        # 과전압 알람 테스트 (bit 0)
        test_data = self.test_discrete_data.copy()
        test_data['status'] = 1  # bit 0 set
        
        result = processor.parse_discrete_data(test_data)
        self.assertTrue(result['alarm_status']['overvoltage'])
        self.assertFalse(result['alarm_status']['overcurrent'])
    
    def test_risk_calculation(self):
        """위험도 계산 테스트"""
        processor = DiscreteDataProcessor()
        
        # 고온 상황 테스트
        high_temp_data = self.test_discrete_data.copy()
        high_temp_data['pcbTemp'] = 70.0
        high_temp_data['sensorTemp'] = 72.0
        
        result = processor.parse_discrete_data(high_temp_data)
        self.assertGreater(
            result['risk_indicators']['total_risk_score'], 
            0.5
        )
    
    @patch('boto3.resource')
    def test_lambda_handler(self, mock_boto3):
        """Lambda 핸들러 테스트"""
        # Mock DynamoDB
        mock_dynamodb = MagicMock()
        mock_boto3.return_value = mock_dynamodb
        
        response = lambda_handler(self.test_discrete_data, {})
        
        self.assertEqual(response['statusCode'], 200)
        body = json.loads(response['body'])
        self.assertEqual(body['device_id'], 'TEST001')

class TestMLModel(unittest.TestCase):
    
    def test_model_prediction_range(self):
        """모델 예측값 범위 테스트"""
        from FirePredictionMLService import RealTimeInferenceEndpoint
        
        endpoint = RealTimeInferenceEndpoint()
        
        test_data = {
            'volt': 220.0,
            'ct': 5.0,
            'pcbTemp': 45.0,
            'sensorTemp': 47.0,
            'co': 10.0,
            'voc': 100.0,
            'aArc': 0,
            'status': 0
        }
        
        with patch.object(endpoint, 'sagemaker_client') as mock_client:
            mock_response = {
                'Body': MagicMock()
            }
            mock_response['Body'].read.return_value.decode.return_value = json.dumps({
                'fire_probability': 0.3,
                'risk_level': 'MEDIUM',
                'confidence': 0.8
            })
            mock_client.invoke_endpoint.return_value = mock_response
            
            result = endpoint.predict_fire_risk(test_data)
            
            self.assertGreaterEqual(result['fire_probability'], 0.0)
            self.assertLessEqual(result['fire_probability'], 1.0)
            self.assertIn(result['risk_level'], 
                         ['NORMAL', 'LOW', 'MEDIUM', 'HIGH', 'CRITICAL'])

if __name__ == '__main__':
    unittest.main()

# 통합 테스트

# python

import boto3

import json
import time
from datetime import datetime

class IntegrationTest:
    def __init__(self, environment='dev'):
        self.environment = environment
        self.iot_client = boto3.client('iot-data')
        self.dynamodb = boto3.resource('dynamodb')
        self.kinesis = boto3.client('kinesis')
        
    def test_end_to_end_flow(self):
        """전체 시스템 End-to-End 테스트"""
        print("🧪 E2E 테스트 시작...")
        
        # 1. 테스트 데이터 전송
        test_device_id = f"TEST_{int(time.time())}"
        test_data = {
            'deviceId': test_device_id,
            'idx': 1,
            'status': 2048,  # 아크 알람
            'volt': 225.0,
            'voltLow': 225.0,
            'ct': 15.0,
            'zct': 2.0,
            'rzct': 1.5,
            'pwr': 3.375,
            'pcbTemp': 55.0,
            'sensorTemp': 58.0,
            'co': 12.0,
            'voc': 200.0,
            'pFct': 0.92,
            'aArc': 3
        }
        
        # IoT Core로 데이터 전송
        topic = f'fire-prediction/device/{test_device_id}/data'
        self.iot_client.publish(
            topic=topic,
            qos=1,
            payload=json.dumps(test_data)
        )
        
        print(f"✅ 테스트 데이터 전송 완료: {test_device_id}")
        
        # 2. 처리 결과 확인 (30초 대기)
        time.sleep(30)
        
        # DynamoDB에서 결과 확인
        raw_data_table = self.dynamodb.Table(f'FirePrediction-RawData-{self.environment}')
        device_state_table = self.dynamodb.Table(f'FirePrediction-DeviceState-{self.environment}')
        
        # 원시 데이터 저장 확인
        response = raw_data_table.query(
            KeyConditionExpression=Key('device_id').eq(test_device_id),
            ScanIndexForward=False,
            Limit=1
        )
        
        assert len(response['Items']) > 0, "원시 데이터가 저장되지 않음"
        print("✅ 원시 데이터 저장 확인")
        
        # 디바이스 상태 업데이트 확인
        device_response = device_state_table.get_item(
            Key={'device_id': test_device_id}
        )
        
        assert 'Item' in device_response, "디바이스 상태가 업데이트되지 않음"
        print("✅ 디바이스 상태 업데이트 확인")
        
        # 3. Kinesis 스트림 확인
        stream_name = f'fire-prediction-stream-{self.environment}'
        
        # 간단한 Kinesis 상태 확인
        stream_desc = self.kinesis.describe_stream(StreamName=stream_name)
        assert stream_desc['StreamDescription']['StreamStatus'] == 'ACTIVE'
        print("✅ Kinesis 스트림 활성 상태 확인")
        
        print("🎉 E2E 테스트 완료!")
        
        return test_device_id
    
    def test_high_load_scenario(self, num_devices=100):
        """고부하 시나리오 테스트"""
        print(f"⚡ 고부하 테스트 시작 ({num_devices}개 디바이스)...")
        
        import concurrent.futures
        import random
        
        def send_test_data(device_num):
            test_data = {
                'deviceId': f'LOAD_TEST_{device_num}',
                'idx': random.randint(1, 1000),
                'status': random.choice([0, 1, 2, 4, 8, 16, 32, 64]),
                'volt': random.uniform(200, 240),
                'voltLow': random.uniform(180, 200),
                'ct': random.uniform(0, 50),
                'zct': random.uniform(0, 10),
                'rzct': random.uniform(0, 5),
                'pwr': random.uniform(0, 10),
                'pcbTemp': random.uniform(20, 80),
                'sensorTemp': random.uniform(20, 80),
                'co': random.uniform(0, 30),
                'voc': random.uniform(0, 1000),
                'pFct': random.uniform(0.7, 1.0),
                'aArc': random.randint(0, 10)
            }
            
            topic = f'fire-prediction/device/LOAD_TEST_{device_num}/data'
            self.iot_client.publish(
                topic=topic,
                qos=1,
                payload=json.dumps(test_data)
            )
            
            return device_num
        
        # 병렬로 데이터 전송
        with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
            futures = [executor.submit(send_test_data, i) for i in range(num_devices)]
            
            for future in concurrent.futures.as_completed(futures):
                device_num = future.result()
                if device_num % 10 == 0:
                    print(f"  📤 {device_num}/{num_devices} 전송 완료")
        
        print("✅ 고부하 테스트 데이터 전송 완료")
        
        # 시스템 응답 시간 모니터링
        time.sleep(60)  # 1분 대기
        
        # CloudWatch 메트릭 확인
        cloudwatch = boto3.client('cloudwatch')
        
        end_time = datetime.now()
        start_time = end_time - timedelta(minutes=5)
        
        # Lambda 오류율 확인
        response = cloudwatch.get_metric_statistics(
            Namespace='AWS/Lambda',
            MetricName='Errors',
            Dimensions=[
                {'Name': 'FunctionName', 'Value': f'fire-prediction-processor-{self.environment}'}
            ],
            StartTime=start_time,
            EndTime=end_time,
            Period=300,
            Statistics=['Sum']
        )
        
        total_errors = sum(point['Sum'] for point in response['Datapoints'])
        error_rate = (total_errors / num_devices) * 100
        
        assert error_rate < 5, f"오류율이 너무 높음: {error_rate}%"
        print(f"✅ 오류율 확인: {error_rate:.2f}%")
        
        print("🎉 고부하 테스트 완료!")

if __name__ == "__main__":
    test = IntegrationTest('dev')
    test.test_end_to_end_flow()
    test.test_high_load_scenario(50)

# 이제 AWS IoT Core 기반 화재 예측 시스템의 전체 구현이 완료되었습니다. 
# 시스템은 Discrete 클래스의 데이터 구조를 완벽하게 지원하며, 실시간 데이터 처리, 머신러닝 기반 예측, 모니터링 및 알림 기능을 모두 포함합니다.